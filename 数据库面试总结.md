# 数据库面试总结

[TOC]

## 数据库基本概念

### **1.主键、外键、超键、候选键**

> **超键**：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
>
> **候选键**：是最小超键，即没有冗余元素的超键。
>
> **主键**：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。
>
> **外键**：在一个表中存在的另一个表的主键称此表的外键。

### **2.为什么用自增列作为主键**

> 如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引、
>
> 如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引、
>
> 如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。
>
> 数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）
>
> 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页
>
> 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

### **3.触发器的作用？**

> 触发器是一种特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。

### **4.什么是存储过程？用什么来调用？**

> 存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。
>
> **调用：**
>
> 1）可以用一个命令对象来调用存储过程。
>
> 2）可以供外部程序调用，比如：java程序。

### **5.存储过程的优缺点？**

> **优点：**
>
> 1）存储过程是预编译过的，执行效率高。
>
> 2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。
>
> 3）安全性高，执行存储过程需要有一定权限的用户。
>
> 4）存储过程可以重复使用，可减少数据库开发人员的工作量。
>
> **缺点：**移植性差

### **6.存储过程与函数的区别**

![img](https://i.imgur.com/ymE9HPJ.png)

### **7.什么叫视图？游标是什么？**

> **视图：**
>
> 是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改会影响基本表。它使得我们获取数据更容易，相比多表查询。
>
> **游标：**
>
> 是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

### **8.视图的优缺点**

> **优点：**
>
> 1对数据库的访问，因为视图可以有选择性的选取数据库里的一部分。
>
> 2)用户通过简单的查询可以从复杂查询中得到结果。
>
> 3)维护数据的独立性，试图可从多个表检索数据。
>
> 4)对于相同的数据可产生不同的视图。
>
> **缺点：**
>
> 性能：查询视图时，必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，那么就无法更改数据

### **9.drop、truncate、 delete区别**

> **最基本：**
>
> - drop直接删掉表。
> - truncate删除表中数据，再插入时自增长id又从1开始。
> - delete删除表中数据，可以加where字句。
>
> （1） DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。
>
> （2） 表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，而DELETE操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。
>
> （3） 一般而言，drop > truncate > delete
>
> （4） 应用范围。TRUNCATE 只能对TABLE；DELETE可以是table和view
>
> （5） TRUNCATE 和DELETE只删除数据，而DROP则删除整个表（结构和数据）。
>
> （6） truncate与不带where的delete ：只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束（constrain),触发器（trigger)索引（index);依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。
>
> （7） delete语句为DML（data maintain Language),这个操作会被放到 rollback segment中,事务提交后才生效。如果有相应的 tigger,执行的时候将被触发。
>
> （8） truncate、drop是DLL（data define language),操作立即生效，原数据不放到 rollback segment中，不能回滚。
>
> （9） 在没有备份情况下，谨慎使用 drop 与 truncate。要删除部分数据行采用delete且注意结合where来约束影响范围。回滚段要足够大。要删除表用drop;若想保留表而将表中数据删除，如果于事务无关，用truncate即可实现。如果和事务有关，或老师想触发trigger,还是用delete。
>
> （10） Truncate table 表名 速度快,而且效率高,因为:?truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。
>
> （11） TRUNCATE TABLE 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子。如果想保留标识计数值，请改用 DELETE。如果要删除表定义及其数据，请使用 DROP TABLE 语句。
>
> （12） 对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带 WHERE 子句的 DELETE 语句。由于 TRUNCATE TABLE 不记录在日志中，所以它不能激活触发器。

### **10.什么是临时表，临时表什么时候删除?**

> **临时表可以手动删除：**
> DROP TEMPORARY TABLE IF EXISTS temp_tb;
>
> **临时表只在当前连接可见，当关闭连接时，MySQL会自动删除表并释放所有空间。因此在不同的连接中可以创建同名的临时表，并且操作属于本连接的临时表。
> 创建临时表的语法与创建表语法类似，不同之处是增加关键字TEMPORARY，**
>
> 如：
>
> CREATE TEMPORARY TABLE tmp_table (
>
> NAME VARCHAR (10) NOT NULL,
>
> time date NOT NULL
> );
>
> select * from tmp_table;

### **11.非关系型数据库和关系型数据库区别，优势比较?**

> **非关系型数据库的优势：**
>
> - **性能：**NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。
> - **可扩展性：**同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。
>
> **关系型数据库的优势：**
>
> - **复杂查询：**可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。
> - **事务支持：**使得对于安全性能很高的数据访问要求得以实现。
>
> **其他：**
>
> **1.**对于这两类数据库，对方的优势就是自己的弱势，反之亦然。
>
> **2.**NOSQL数据库慢慢开始具备SQL数据库的一些复杂查询功能，比如MongoDB。
>
> **3.**对于事务的支持也可以用一些系统级的原子操作来实现例如乐观锁之类的方法来曲线救国，比如Redis set nx。

### **12.数据库范式，根据某个场景设计数据表?**

> **第一范式:**(确保每列保持原子性)所有字段值都是不可分解的原子值。
>
> 第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。
> 第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式，如下表所示。
> 上表所示的用户信息遵循了第一范式的要求，这样在对用户使用城市进行分类的时候就非常方便，也提高了数据库的性能。
>
> **第二范式:**(确保表中的每列都和主键相关)在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。
>
> 第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。
> 比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键。
>
> **第三范式:**(确保每列都和主键列直接相关,而不是间接相关) 数据表中的每一列数据都和主键直接相关，而不能间接相关。
>
> 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。
> 比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。
>
> **BCNF:**符合3NF，并且，主属性不依赖于主属性。
>
> 若关系模式属于第二范式，且每个属性都不传递依赖于键码，则R属于BC范式。
> 通常BC范式的条件有多种等价的表述：每个非平凡依赖的左边必须包含键码；每个决定因素必须包含键码。
> BC范式既检查非主属性，又检查主属性。当只检查非主属性时，就成了第三范式。满足BC范式的关系都必然满足第三范式。
> 还可以这么说：若一个关系达到了第三范式，并且它只有一个候选码，或者它的每个候选码都是单属性，则该关系自然达到BC范式。
> 一般，一个数据库设计符合3NF或BCNF就可以了。
>
> **第四范式:**要求把同一表内的多对多关系删除。
>
> **第五范式:**从最终结构重新建立原始结构。

### **13.什么是 内连接、外连接、交叉连接、笛卡尔积等?**

> **内连接:** 只连接匹配的行
>
> **左外连接:** 包含左边表的全部行（不管右边的表中是否存在与它们匹配的行），以及右边表中全部匹配的行
>
> **右外连接:** 包含右边表的全部行（不管左边的表中是否存在与它们匹配的行），以及左边表中全部匹配的行
>
> 例如1：
> SELECT a.*,b.* FROM luntan LEFT JOIN usertable as b ON a.username=b.username
>
> 例如2：
> SELECT a.*,b.* FROM city as a FULL OUTER JOIN user as b ON a.username=b.username
>
> **全外连接:** 包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行。
>
> **交叉连接:** 生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将一个数据源中的每个行与另一个数据源的每个行都一一匹配
>
> 例如：
> SELECT type,pub_name FROM titles CROSS JOIN publishers ORDER BY type
>
> **注意：**
>
> 很多公司都只是考察是否知道其概念，但是也有很多公司需要不仅仅知道概念，还需要动手写sql,一般都是简单的连接查询，具体关于连接查询的sql练习，参见以下链接：
>
> [牛客网数据库SQL实战](https://www.nowcoder.com/ta/sql)
>
> [leetcode中文网站数据库练习](https://leetcode-cn.com/problemset/database/)
>
> [我的另一篇文章，常用sql练习50题](http://www.baidu.com/)

### **14.varchar和char的使用场景?**

> 

> **1.**char的长度是不可变的，而varchar的长度是可变的。
>
> 定义一个char[10]和varchar[10]。
> 如果存进去的是‘csdn’,那么char所占的长度依然为10，除了字符‘csdn’外，后面跟六个空格，varchar就立马把长度变为4了，取数据的时候，char类型的要用trim()去掉多余的空格，而varchar是不需要的。
>
> **2.**char的存取速度还是要比varchar要快得多，因为其长度固定，方便程序的存储与查找。
> char也为此付出的是空间的代价，因为其长度固定，所以难免会有多余的空格占位符占据空间，可谓是以空间换取时间效率。
> varchar是以空间效率为首位。
>
> **3.**char的存储方式是：对英文字符（ASCII）占用1个字节，对一个汉字占用两个字节。
> varchar的存储方式是：对每个英文字符占用2个字节，汉字也占用2个字节。
>
> **4.**两者的存储数据都非unicode的字符数据。

### **15.SQL语言分类**

> **SQL语言共分为四大类：**
>
> - 数据查询语言DQL
> - 数据操纵语言DML
> - 数据定义语言DDL
> - 数据控制语言DCL。
>
> **1. 数据查询语言DQL**
>
> 数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块：
>
> SELECT
> FROM
> WHERE
>
> **2 .数据操纵语言DML**
>
> 数据操纵语言DML主要有三种形式：
>
> 1. 插入：INSERT
> 2. 更新：UPDATE
> 3. 删除：DELETE
>
> **3. 数据定义语言DDL**
>
> 数据定义语言DDL用来创建数据库中的各种对象-----表、视图、索引、同义词、聚簇等如：
> CREATE TABLE/VIEW/INDEX/SYN/CLUSTER
>
> 表 视图 索引 同义词 簇
>
> DDL操作是隐性提交的！不能rollback
>
> **4. 数据控制语言DCL**
>
> 数据控制语言DCL用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果，对数据库实行监视等。如：
>
> 1. GRANT：授权。
> 2. ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点。回滚---ROLLBACK；回滚命令使数据库状态回到上次最后提交的状态。其格式为：
>    SQL>ROLLBACK;
> 3. COMMIT [WORK]：提交。
>
> 在数据库的插入、删除和修改操作时，只有当事务在提交到数据
> 库时才算完成。在事务提交前，只有操作数据库的这个人才能有权看
> 到所做的事情，别人只有在最后提交完成后才可以看到。
> 提交数据有三种类型：显式提交、隐式提交及自动提交。下面分
> 别说明这三种类型。
>
> (1) 显式提交
> 用COMMIT命令直接完成的提交为显式提交。其格式为：
> SQL>COMMIT；
>
> (2) 隐式提交
> 用SQL命令间接完成的提交为隐式提交。这些命令是：
> ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，
> EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME。
>
> (3) 自动提交
> 若把AUTOCOMMIT设置为ON，则在插入、修改、删除语句执行后，
> 系统将自动进行提交，这就是自动提交。其格式为：
> SQL>SET AUTOCOMMIT ON；
>
> 参考文章：
> https://www.cnblogs.com/study-s/p/5287529.html

### **16.like %和-的区别**

> **通配符的分类:**
>
> **%百分号通配符:**表示任何字符出现任意次数(可以是0次).
>
> **_下划线通配符:**表示只能匹配单个字符,不能多也不能少,就是一个字符.
>
> **like操作符:** LIKE作用是指示mysql后面的搜索模式是利用通配符而不是直接相等匹配进行比较.
>
> **注意:** 如果在使用like操作符时,后面的没有使用通用匹配符效果是和=一致的,SELECT * FROM products WHERE products.prod_name like '1000';
> 只能匹配的结果为1000,而不能匹配像JetPack 1000这样的结果.
>
> - %通配符使用: 匹配以"yves"开头的记录:(包括记录"yves") SELECT *FROM products WHERE products.prod_name like 'yves%';
>   匹配包含"yves"的记录(包括记录"yves") SELECT* FROM products WHERE products.prod_name like '%yves%';
>   匹配以"yves"结尾的记录(包括记录"yves",不包括记录"yves ",也就是yves后面有空格的记录,这里需要注意) SELECT * FROM products WHERE products.prod_name like '%yves';
> - *通配符使用: SELECT \*FROM products WHERE products.prod_name like '_yves'; 匹配结果为: 像"yyves"这样记录.
>   SELECT\* FROM products WHERE products.prod\*name like 'yves**'; 匹配结果为: 像"yvesHe"这样的记录.(一个下划线只能匹配一个字符,不能多也不能少)
>
> **注意事项:**
>
> - 注意大小写,在使用模糊匹配时,也就是匹配文本时,mysql是可能区分大小的,也可能是不区分大小写的,这个结果是取决于用户对MySQL的配置方式.如果是区分大小写,那么像YvesHe这样记录是不能被"yves__"这样的匹配条件匹配的.
> - 注意尾部空格,"%yves"是不能匹配"heyves "这样的记录的.
> - 注意NULL,%通配符可以匹配任意字符,但是不能匹配NULL,也就是说SELECT * FROM products WHERE products.prod_name like '%;是匹配不到products.prod_name为NULL的的记录.
>
> **技巧与建议:**
>
> 正如所见， MySQL的通配符很有用。但这种功能是有代价的：通配符搜索的处理一般要比前面讨论的其他搜索所花时间更长。这里给出一些使用通配符要记住的技巧。
>
> - 不要过度使用通配符。如果其他操作符能达到相同的目的，应该 使用其他操作符。
> - 在确实需要使用通配符时，除非绝对有必要，否则不要把它们用 在搜索模式的开始处。把通配符置于搜索模式的开始处，搜索起 来是最慢的。
> - 仔细注意通配符的位置。如果放错地方，可能不会返回想要的数.

参考博文：https://blog.csdn.net/u011479200/article/details/78513632

### **17.count(\*)、count(1)、count(column)的区别**

> - count(*)对行的数目进行计算,包含NULL
> - count(column)对特定的列的值具有的行数进行计算,不包含NULL值。
> - count()还有一种使用方式,count(1)这个用法和count(*)的结果是一样的。
>
> **性能问题:**
>
> 1.任何情况下SELECT COUNT(*) FROM tablename是最优选择;
>
> 2.尽量减少SELECT COUNT(*) FROM tablename WHERE COL = ‘value’ 这种查询;
>
> 3.杜绝SELECT COUNT(COL) FROM tablename WHERE COL2 = ‘value’ 的出现。
>
> - 如果表没有主键,那么count(1)比count(*)快。
> - 如果有主键,那么count(主键,联合主键)比count(*)快。
> - 如果表只有一个字段,count(*)最快。
>
> count(1)跟count(主键)一样,只扫描主键。count(*)跟count(非主键)一样,扫描整个表。明显前者更快一些。

### **18.最左前缀原则**

> **多列索引：**
>
> ALTER TABLE people ADD INDEX lname_fname_age (lame,fname,age);
>
> 为了提高搜索效率，我们需要考虑运用多列索引,由于索引文件以B－Tree格式保存，所以我们不用扫描任何记录，即可得到最终结果。
>
> 注：在mysql中执行查询时，只能使用一个索引，如果我们在lname,fname,age上分别建索引,执行查询时，只能使用一个索引，mysql会选择一个最严格(获得结果集记录数最少)的索引。
>
> **最左前缀原则：**顾名思义，就是最左优先，上例中我们创建了lname_fname_age多列索引,相当于创建了(lname)单列索引，(lname,fname)组合索引以及(lname,fname,age)组合索引。

## SQL语法

见[runoob菜鸟教程](https://www.runoob.com/sql/sql-tutorial.html)

## 事务的四大特性

### 四大特性/ACID

![图片说明](https://uploadfiles.nowcoder.com/images/20210330/972694929_1617119642496/787AE2E621C6DA8A84B81E9CF1C40BAA)
**原子性/atomicity** 

一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。

保持事务的原子性是指操作发生异常时，需要对该事务所有之前执行过的操作进行回滚。首先要设置autocommit=0，就是默认不能隐式提交，需要手动commit提交。回滚需要**undo日志**实现，undo日志存放之前修改过的记录，事务发生异常触发roll back，会按照日志逻辑回滚undo日志的操作。

**一致性/consistency**

事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。

一致性可以理解为事务对**数据完整性约束**的遵循。事务执行前后都是合法的数据状态，不会违背任何数据完整性

从数据库层面，数据库通过原子性、隔离性、持久性来保持一致性。

**隔离性/isolation**

一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。

用锁和隔离机制。锁是需要用户自己定义的，隔离机制是数据库提供的。

**持久性/durability**

持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

在无并发事务的情况下，持久性依赖于原子性；在有并发事务的情况下，持久性依赖于原子性和隔离性

即使数据库系统遇到故障也不会丢失已提交事务的操作，通过redo日志来实现的。基本步骤如下图 ：①当在事务中尝试对数据进行更改时；②首先将数据从磁盘读入内存，更新内存缓存的数据。③生成一条redo日志缓存，放在redo日志的缓冲区；④事务真正提交时将缓冲区中的日志写入redo日志做持久化保存；⑤把内存中的数据同步到磁盘上。



### **隔离级别**⭐⭐

在并发状态下，事务会出现一些问题，主要有三种问题：

**脏读** 一个事务能读到另外一个事务没有提交的数据。（举例：A给B转了100块，但是A转完并没有提交该事务，B读到了自己的账户多了100块，此时A发现转账错误之后就回滚了该操作，此时就称为脏读）

**不可重复读** 一个事务的两次查询操作数据不一致，可能是两次查询过程中插入了一个事务更新了原有的数据（举例：两个并发事务A和B，A首先查询自己的账户是100块，B此时提走了A账户的50块，A再次查询发现此时账户只剩下了50块，两次查询操作结果不同）

**幻读** 在一个事务的两次查询中数据不一致，发现了原来没有的数据或者原有的数据不见了

> 不可重复读与幻读相似，不可重复读侧重于另一个事务对数据库的**修改**操作，而幻读则侧重于另一个事务对数据库的**增加**和**删除**操作

#### Ⅰ.读未提交（Read uncommitted）

这种事务隔离级别下，select语句不加锁。

允许读取另一个事务尚未提交的数据，可能会造成脏读、不可重复读、幻读

#### Ⅱ.读已提交（Read committed）

允许读取并发事务已经提交了的数据，可以阻止脏读，但是不能避免不可重复读和幻读

在互联网大数据量，高并发量的场景下，几乎 **不会使用** 上述两种隔离级别。

#### Ⅲ.可重复读（Repeatable read）

会保持共享锁到事务结束。

在一个事务的操作过程中，不能读取到别的事务对该数据库的修改增删操作，可以阻止脏读和不可重复读，但是不能避免幻读（mysql默认级别）

#### Ⅳ.串行化（Serializable ）

不仅会锁定影响的数据，还会锁定这个范围

所有的事务依次逐个执行，当表被一个事务操作时，其他事务的操作不可以进行，进入排队状态，等待当前操作事务提交后才能继续执行操作。

## 锁

按使用方式分为**乐观锁**、**悲观锁**

按粒度分为表级锁、**行级锁**、页级锁 （InnoDB支持行级锁、表锁，MyISAM只支持表锁）

锁的粒度越小，系统开销越大，但相应的并发性就越高。因此选择锁粒度的时候需要在系统开销和并发性间权衡。

锁的类型上划分为**互斥锁/写锁/X锁、共享锁/读锁/S锁**

共享锁：对某一资源加共享锁，自身可以读该资源，其他人也可以读该资源
共享锁（S锁）：如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。
排他锁（X锁）：如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。
共享锁下其它用户可以并发读取，查询数据。但不能修改，增加，删除数据。资源共享。

### **1.mysql都有什么锁，死锁判定原理和具体场景，死锁怎么解决?**

> **MySQL有三种锁的级别：**页级、表级、行级。
>
> - **表级锁：**开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。
> - **行级锁：**开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。
> - **页面锁：**开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般
>   **什么情况下会造成死锁?**
>
> **什么是死锁？**
>
> **死锁:** 是指两个或两个以上的进程在执行过程中。因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程。
>
> 表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB。
>
> **死锁的关键在于：**两个(或以上)的Session加锁的顺序不一致。
>
> 那么对应的解决死锁问题的关键就是：让不同的session加锁有次序。
>
> **死锁的解决办法?**
>
> 1.查出的线程杀死 kill
> SELECT trx_MySQL_thread_id FROM information_schema.INNODB_TRX;
>
> 2.设置锁的超时时间
> Innodb 行锁的等待时间，单位秒。可在会话级别设置，RDS 实例该参数的默认值为 50（秒）。
>
> 生产环境不推荐使用过大的 innodb_lock_wait_timeout参数值
> 该参数支持在会话级别修改，方便应用在会话级别单独设置某些特殊操作的行锁等待超时时间，如下：
> set innodb_lock_wait_timeout=1000; —设置当前会话 Innodb 行锁等待超时时间，单位秒。
>
> 3.指定获取锁的顺序

### **2.有哪些锁（乐观锁悲观锁），select 时怎么加排它锁?**

> **悲观锁（Pessimistic Lock）:**
>
> **悲观锁特点:**先获取锁，再进行业务操作。
>
> 即“悲观”的认为获取锁是非常有可能失败的，因此要先确保获取锁成功再进行业务操作。通常所说的**“一锁二查三更新”即指的是使用悲观锁。**通常来讲在数据库上的悲观锁需要数据库本身提供支持，即通过常用的select … for update操作来实现悲观锁。当数据库执行select for update时会获取被select中的数据行的行锁，因此其他并发执行的select for update如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。
>
> **补充：**
> 不同的数据库对select for update的实现和支持都是有所区别的，
>
> - oracle支持select for update no wait，表示如果拿不到锁立刻报错，而不是等待，MySQL就没有no wait这个选项。
> - MySQL还有个问题是select for update语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。因此如果在MySQL中用悲观锁务必要确定走了索引，而不是全表扫描。
>
> **乐观锁（Optimistic Lock）:**
>
> **1.**乐观锁，也叫乐观并发控制，它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，那么当前正在提交的事务会进行回滚。
>
> **2.\**\**乐观锁的特点先进行业务操作，不到万不得已不去拿锁。**即“乐观”的认为拿锁多半是会成功的，因此在进行完业务操作需要实际更新数据的最后一步再去拿一下锁就好。
> 乐观锁在数据库上的实现完全是逻辑的，不需要数据库提供特殊的支持。
>
> **3.**一般的做法是**在需要锁的数据上增加一个版本号，或者时间戳**，
>
> **实现方式举例如下：**
>
> **乐观锁（给表加一个版本号字段）** 这个并不是乐观锁的定义，给表加版本号，是**数据库实现乐观锁的一种方式**。
>
> 1. SELECT data AS old_data, version AS old_version FROM …;
> 2. 根据获取的数据进行业务操作，得到new_data和new_version
> 3. UPDATE SET data = new_data, version = new_version WHERE version = old_version
>
> if (updated row > 0) {
>
> // 乐观锁获取成功，操作完成
>
> } else {
>
> // 乐观锁获取失败，回滚并重试
>
> }
>
> **注意：**
>
> - 乐观锁在不发生取锁失败的情况下开销比悲观锁小，但是一旦发生失败回滚开销则比较大，因此适合用在取锁失败概率比较小的场景，可以提升系统并发性能
> - 乐观锁还适用于一些比较特殊的场景，例如在业务操作过程中无法和数据库保持连接等悲观锁无法适用的地方。
>
> **总结：**
> 悲观锁和乐观锁是数据库用来保证数据并发安全防止更新丢失的两种方法，例子在select ... for update前加个事务就可以防止更新丢失。悲观锁和乐观锁大部分场景下差异不大，一些独特场景下有一些差别，一般我们可以从如下几个方面来判断。
>
> - **响应速度：** 如果需要非常高的响应速度，建议采用乐观锁方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁。'
> - **冲突频率：** 如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大。
> - **重试代价：** 如果重试代价大，建议采用悲观锁。

## InnoDB和MyISAM索引的区别

![图片说明](https://uploadfiles.nowcoder.com/images/20210331/972694929_1617161101806/072774B6B658B3603E1AA7198722775C)Innodb引擎：提供了对数据库ACID事务的支持，并且实现了sql标准的四种隔离级别，事务安全的，支持行级锁，不支持全文索引。
MyIASM引擎：mysql的默认引擎，没有提供对数据库事务的支持，非事务安全的，锁的粒度是表级的，支持全文索引类型，相对简单性能优。
总结：
MYIASM管理非事务表，提供高速存储和检索，以及全文搜索能力，如果在应用中执行大量的select操作，应选择MYIASM引擎
Innodb用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量的insert和update操作，应选择innodb引擎。



## 索引

### 索引定义

索引能快速找到**某一列中有一特定值**的行。不必挨个儿去查看记录的内容。索引是对数据库中一列或者多列的值进行[排序]()的一种**数据结构**，以索引文件的形式存储在磁盘上，占据一定的物理空间

### 索引优点

1.提高查询的性能，大大减少表的检索行数

2.可以建立唯一索引或者主键索引，保证数据库中每一行数据的唯一性

3.加速表与表之间的连接，特别是在实现数据的参考完整性方面特别有意义。

4.在使用分组group by和排序order by子句进行数据检索时，可以显著减少查询中分组和排序的时间（数据库的记录会重新排序）

5.通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。

### 索引缺点

1.索引文件占据物理空间(空间)

2.对表中数据进行增删改查时，索引也要动态地维护，降低了数据的维护速度(时间)

### 索引的分类

**唯一索引** 数据列不允许重复但是允许为null，一个表允许多列创建多个**唯一索引**

**主键索引** 数据列不允许重复，也不允许为null，**一个表中只能有一个主键，但是可以有多个列共同组成的联合主键**

**普通索引** 没有唯一性的限制，允许为null，只是简单的加速查询

**联合索引** 多个索引的组合,必须满足最左前缀原则

**全文索引** 查找全文中的关键字, mysql的Innodb引擎不支持 myISAM引擎支持

### 索引设计原则

1.对查询频次较高、数据量较大的表建立索引

2.使用唯一索引，区分度越高，使用索引的效率越高

3.使用短索引，减少存储空间，提升I/O效率

4.利用最左前缀，在组合索引中比如有(name,city,age)的话，只支持(name)、(name,city)、(name,city,age)这三种组合的检索，查询时必须包含索引的最左列，不能跳过某个字段进行查询

5.为经常需要排序 分组和联合操作的字段建立索引

6.限制索引的数目,索引并非越多越好

### 推荐使用索引的场景

（1）在经常需要搜索的列上，可以加快搜索的速度；

（2）在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；

（3）在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；

（4）在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；

（5）在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；

（6）在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。

### 不推荐使用索引的场景

1. 数据唯一性比较差，**重复比较多**的情况下不要使用索引
2. **频繁更新**的字段不适用索引（导致索引维护困难）
3. 对于那些在查询中很少使用或者参考的列不应该创建索引。
4. 对于那些定义为text, image和bit数据类型的列不应该增加索引。

### 索引失效的场景

1. 复合索引不满足最左前缀原则 
2. 模糊查找时like ‘%'以%开头 
3. where索引列有运算 
4. where索引列有函数 
5. mysql估计用全表扫描要比用索引更快,则不使用索引 
6. 查询条件中有or的话可能会造成索引失效,除非or的每个列都加上索引 



### 索引的数据结构

#### B树

![图片说明](https://uploadfiles.nowcoder.com/images/20210331/972694929_1617160719273/D5E01A50D0CD20B22E158BD19257DF2E)
这里被遮住的字符是 [ceil(m/2)-1]<=n<=m-1
**优点**：层级结构较低，且冗余节点较少

#### B+树

1. n叉B+树最多含有n个key，B树最多含有n-1个key

2. B+树的叶子节点保存所有的键值信息和数据，依key大小[排序]()，所有的非叶子节点只存储键值，所有的叶子节点都通过指针连接在一起，形成了一个有序[链表]()（支持翻页）。(B树中每个节点都存储有键值和数据）

   > 支持翻页：每个磁盘块存储一个节点，称为一页。连续查询多个节点则称为翻页

3. **优势**：相同数据集来说B+树的层级结构比[二叉树]()、B树小，因此搜索速度更快；查询任何key都要从root走到叶子，因此**查询效率更稳定**；所有数据均有序存储在叶子节点，使得范围查找、[排序]()查找、去重查找变得简单易行（B树数据分布在各个节点，包括非叶子节点，不便于范围等查找）

4. **缺陷**：因为有冗余节点数据，因此会造成内存的浪费

#### hash

**特点：**
1.hash表是key-value形式，通过一个散列函数，能够根据key快速找到对应的value

2.检索时无需使用树状结构那样从根节点到叶子节点逐级查找，只需要一次hash[算法]()即可定位到相应位置，速度较快

**hash索引的缺点**

1.hash索引只能够进行单值查找，不支持范围查询，而B+树支持范围查询（hash函数过滤后的键值大小关系不能保证和源数据的大小关系一致）

2.hash索引不能利用索引完成[排序]()，以及像like 'xxx%'这样的模糊查询（本质上也是一种范围查询）

3.hash索引不支持多列联合索引的**最左匹配**原则

4.hash索引在重复值较高的时候，因为存在**哈希碰撞**导致性能极低。

5.hash索引只适用于存储数据重复度很低、对数据等值查询、无[排序]()和范围查询的情况，效率较高。

#### **为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？**

> **1.B+的磁盘读写代价更低**
>
> B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。
>
> **2.B+tree的查询效率更加稳定**
>
> 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。



## 优化

### **1.查询语句不同元素（where、jion、limit、group by、having等等）执行先后顺序?**

- 1.查询中用到的关键词主要包含**六个**，并且他们的顺序依次为 **select--from--where--group by--having--order by**

> **其中select和from是必须的，其他关键词是可选的，这六个关键词的执行顺序 与sql语句的书写顺序并不是一样的，而是按照下面的顺序来执行**
>
> **from:**需要从哪个数据表检索数据

> **where:**过滤表中数据的条件
>
> **group by:**如何将上面过滤出的数据分组
>
> **having:**对上面已经分组的数据进行过滤的条件
>
> **select:**查看结果集中的哪个列，或列的计算结果
>
> **order by :**按照什么样的顺序来查看返回的数据

- 2.**from后面的表关联，是自右向左解析 而where条件的解析顺序是自下而上的。**

> 也就是说，在写SQL语句的时候，尽量把数据量小的表放在最右边来进行关联（用小表去匹配大表），而把能筛选出小量数据的条件放在where语句的最左边 （用小表去匹配大表）
>
> 其他参考资源：
> http://www.cnblogs.com/huminxxl/p/3149097.html

### **2.使用explain优化sql和索引?**

> **对于复杂、效率低的sql语句，我们通常是使用explain sql 来分析sql语句，这个语句可以打印出，语句的执行。这样方便我们分析，进行优化**
>
> **table：**显示这一行的数据是关于哪张表的
>
> **type：**这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL
>
> **all:**full table scan ;MySQL将遍历全表以找到匹配的行；
>
> **index:** index scan; index 和 all的区别在于index类型只遍历索引；
>
> **range：**索引范围扫描，对索引的扫描开始于某一点，返回匹配值的行，常见与between ，等查询；
>
> **ref：**非唯一性索引扫描，返回匹配某个单独值的所有行，常见于使用非唯一索引即唯一索引的非唯一前缀进行查找；
>
> **eq_ref：**唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常用于主键或者唯一索引扫描；
>
> **const，system：**当MySQL对某查询某部分进行优化，并转为一个常量时，使用这些访问类型。如果将主键置于where列表中，MySQL就能将该查询转化为一个常量。
>
> **possible_keys：**显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句
>
> **key：** 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MySQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MySQL忽略索引
>
> **key_len：**使用的索引的长度。在不损失精确性的情况下，长度越短越好
>
> **ref：**显示索引的哪一列被使用了，如果可能的话，是一个常数
>
> **rows：**MySQL认为必须检查的用来返回请求数据的行数
>
> **Extra：**关于MySQL如何解析查询的额外信息。将在表4.3中讨论，但这里可以看到的坏的例子是Using temporary和Using filesort，意思MySQL根本不能使用索引，结果是检索会很慢。

### **3.MySQL慢查询怎么解决?**

> - slow_query_log 慢查询开启状态。
> - slow_query_log_file 慢查询日志存放的位置（这个目录需要MySQL的运行帐号的可写权限，一般设置为MySQL的数据存放目录）。
> - long_query_time 查询超过多少秒才记录。

## Redis

### 简介

Redis 是一个开源的使用 ANSI C 语言编写、遵守 BSD 协议、支持网络、可基于内存亦可持久化的日志型、**Key-Value 数据库**，并提供多种语言的 API的非关系型数据库。

传统数据库遵循 ACID 规则。而 Nosql（Not Only SQL 的缩写，是对不同于传统的关系型数据库的数据库管理系统的统称） 一般为分布式而分布式一般遵循 CAP 定理。

### 为什么要用 redis /为什么要用缓存

主要从“高性能”和“高并发”这两点来看待这个问题。

**高性能：**

假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在数缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！

![img](https:////upload-images.jianshu.io/upload_images/14534869-67f18efcafe4669a.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/729/format/webp)

image

**高并发：**

直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

![img](https:////upload-images.jianshu.io/upload_images/14534869-09b1d279a05ef5bc.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/554/format/webp)

### redis 和 memcached 的区别

对于 redis 和 memcached 的区别有下面四点。

1. **redis支持更丰富的数据类型（支持更复杂的应用场景）**：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。
2. **Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。**
3. **集群模式**：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.
4. **Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。**

![img](https:////upload-images.jianshu.io/upload_images/14534869-18daca8516e46c3a.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/621/format/webp)

### redis 常见数据结构以及使用场景分析

#### 1. String

> **常用命令:** set,get,decr,incr,mget 等。
>
> **格式**: set key value

String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 常规key-value缓存应用； 常规计数：微博数，粉丝数等。

#### 2.Hash

> **常用命令：** hget,hset,hgetall 等。
>
> **格式**: hmset name key1 value1 key2 value2

Hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以Hash数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：



```csharp
key=JavaUser293847
value={
  “id”: 1,
  “name”: “SnailClimb”,
  “age”: 22,
  “location”: “Wuhan, Hubei”
}
```

#### 3.List

> **常用命令:** lpush,rpush,lpop,rpop,lrange等
>
> **格式**: lpush name value
>
> 在 key 对应 list 的头部添加字符串元素
>
> 格式: rpush name value
>
> 在 key 对应 list 的尾部添加字符串元素
>
> 格式: lrem name index
>
> key 对应 list 中删除 count 个和 value 相同的元素
>
> 格式: llen name 
>
> 返回 key 对应 list 的长度

list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。

Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。

#### 4.Set

> **常用命令：** sadd,spop,smembers,sunion 等
>
> **格式**: sadd name value

set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。

当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。

比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：



```undefined
sinterstore key1 key2 key3     将交集存在key1内
```

#### 5.Sorted Set/zset

> **常用命令：** zadd,zrange,zrem,zcard等
>
> **格式**: zadd name score value

和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。

zset的成员是唯一的,但分数(score)却可以重复。

**举例：** 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 SortedSet 结构进行存储。

### **什么是Redis持久化？Redis有哪几种持久化方式？优缺点是什么？**

持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。

Redis 提供了两种持久化方式:**RDB**（默认） 和**AOF** 

#### **快照（snapshotting）持久化（RDB）**

rdb是Redis DataBase缩写

功能核心函数rdbSave(生成RDB文件)和rdbLoad（从文件加载内存）两个函数

![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925141429889-1694430603.png)

Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。

#### **AOF（append-only file）持久化**

Aof是Append-only file缩写

![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925141527592-2105439510.png)

每当执行服务器(定时)任务或者函数时flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作

aof写入保存：

WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件

SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。

与快照持久化相比，AOF持久化 的**实时性**更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：

```aof
appendonly yes
```

开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。

在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

```bash
appendfsync always     #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no      #让操作系统决定何时进行同步
```

为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。



**存储结构:**

 内容是redis通讯协议(RESP )格式的命令文本存储。

**比较**：

1、aof文件比rdb更新频率高，优先使用aof还原数据。

2、aof比rdb更安全也更大

3、rdb性能比aof好

4、如果两个都配了优先加载AOF

### **Redis 有哪些架构模式？讲讲各自的特点**

####  **单机版**

![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142100480-1152515615.png)

特点：简单

问题：

1、内存容量有限 2、处理能力有限 3、无法高可用。

#### **主从复制**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142118041-1727225479.png)**

Redis 的复制（replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。 只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。

特点：

1、master/slave 角色

2、master/slave 数据相同

3、降低 master 读压力在转交从库

问题：

无法保证高可用

没有解决 master 写的压力

#### **哨兵**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142143478-1454265814.png)**

Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。其中三个特性：

监控（Monitoring）：  Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。

提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。

自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。

特点：

1、保证高可用

2、监控各个节点

3、自动故障迁移

缺点：主从模式，切换需要时间丢数据

没有解决 master 写的压力

#### **集群（直连型）：**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142304757-1498788186.png)**

从redis 3.0之后版本支持redis-cluster集群，Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。

特点：

1、无中心架构（不存在哪个节点影响性能瓶颈），少了 proxy 层。

2、数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。

3、可扩展性，可线性扩展到 1000 个节点，节点可动态添加或删除。

4、高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本

5、实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave到 Master 的角色提升。

缺点：

1、资源隔离性较差，容易出现相互影响的情况。

2、数据通过异步复制,不保证数据的强一致性

### 缓存雪崩和缓存穿透问题解决方案

#### **缓存雪崩**

简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决办法：

- 事前：

  - 尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
  - 二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期
  - 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

- 事中：

  - 本地ehcache缓存 + hystrix限流&降级，避免MySQL崩掉
  - 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。

- 事后：利用 redis 持久化机制保存的数据尽快恢复缓存

  

![img](https://upload-images.jianshu.io/upload_images/14534869-cefa2f5519af3a09.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

#### **缓存穿透**

简介：一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决办法： 有很多种方法可以有效地解决缓存穿透问题，

- 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

- 另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

