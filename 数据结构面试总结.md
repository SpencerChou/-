# 数据结构面试总结

[toc]



## 数组

数组是最简单、也是使用最广泛的数据结构。栈、队列等其他数据结构均由数组演变而来。

每个数据元素都关联一个正数值，我们称之为索引，它表明数组中每个元素所在的位置。大部分语言将初始索引定义为零。

以下是数组的两种类型：

- 一维数组(如上所示)
- 多维数组(数组的数组)

数组的基本操作

- Insert——在指定索引位置插入一个元素
- Get——返回指定索引位置的元素
- Delete——删除指定索引位置的元素
- Size——得到数组所有元素的数量

面试中关于数组的常见问题

- 寻找数组中第二小的元素
- 找到数组中第一个不重复出现的整数
- 合并两个有序数组
- 重新排列数组中的正值和负值

##### 详情见leetcode的数组相关习题

## 链表

链表是另一个重要的线性数据结构，乍一看可能有点像数组，但在内存分配、内部结构以及数据插入和删除的基本操作方面均有所不同。

链表就像一个节点链，其中每个节点包含着数据和指向后续节点的指针。 链表还包含一个头指针，它指向链表的第一个元素，但当列表为空时，它指向null或无具体内容。

链表一般用于实现文件系统、哈希表和邻接表。

链表包括以下类型：

- 单链表(单向)
- 双向链表(双向)

链表的基本操作：

- InsertAtEnd - 在链表的末尾插入指定元素
- InsertAtHead - 在链接列表的开头/头部插入指定元素
- Delete - 从链接列表中删除指定元素
- DeleteAtHead - 删除链接列表的第一个元素
- Search - 从链表中返回指定元素
- isEmpty - 如果链表为空，则返回true

面试中关于链表的常见问题

- 反转链表
- 检测链表中的循环
- 返回链表倒数第N个节点
- 删除链表中的重复项





单链表：只有data和next

​	插入：q.next = p.next（插入q）

​				p.next = q

​	删除：p.next = q.next（删除q）

双链表：多了一个prev

​	插入：q.prev = p （q待插入）

​				q.next = p.next

​				p.next = q

​				q.next.prev = p

​	删除：p.prev.next = p.next（删除p）

​				p-next.prev = p.prev

​				p.next = p.prev = None

##### 详情见leetcode的链表相关习题



## 栈

著名的撤销操作几乎遍布任意一个应用。但你有没有思考过它是如何工作的呢?这个问题的解决思路是按照将最后的状态排列在先的顺序，在内存中存储历史工作状态。这没办法用数组实现。但有了栈，这就变得非常方便了。

可以把栈想象成一列垂直堆放的书。为了拿到中间的书，你需要移除放置在这上面的所有书。这就是LIFO(后进先出)的工作原理。

栈的基本操作

- Push——在顶部插入一个元素
- Pop——返回并移除栈顶元素
- isEmpty——如果栈为空，则返回true
- Top——返回顶部元素，但并不移除它

面试中关于栈的常见问题

- 使用栈计算后缀表达式

- 对栈的元素进行排序

- 判断表达式是否括号平衡

- 设计含最小函数min()的栈，要求min、push、pop、的时间复杂度都是O(1)。min方法的作用是：就能返回是栈中的最小值。【微信面试题】
  普通思路：

  　　一般情况下，我们可能会这么想：利用min变量，每次添加元素时，都和min元素作比较，这样的话，就能保证min存放的是最小值。但是这样的话，会存在一个问题：如果最小的元素出栈了，那怎么知道剩下的元素中哪个是最小的元素呢？

  改进思路：

  这里需要加一个辅助栈，用空间换取时间。辅助栈中，栈顶永远保存着当前栈中最小的数值。具体是这样的：原栈中，每次添加一个新元素时，就和辅助栈的栈顶元素相比较，如果新元素小，就把新元素的值放到辅助栈和原栈中，如果新元素大，就把元素放到原栈中；出栈时，如果原栈跟辅助栈元素相同，都弹出，否则只弹出原栈栈顶元素

- #### 两个栈实现一个队列：

  思路：

  **栈1用于存储元素，栈2用于弹出元素，负负得正。**

  **用栈1负责来添加操作，用栈2来实现弹出操作；如果栈2里面有元素，直接弹出，没有元素，判断栈1，栈1没有元素，返回错误；栈1有元素，则将栈1里面的元素都弹到栈2，然后从栈2中弹出元素。**

- 火车进站问题：顺序进入，输出合法序列

  - 输出序列中的任何一个数，它后面所有比它小的数应当倒序排列。

## 队列

与栈相似，队列是另一种顺序存储元素的线性数据结构。栈与队列的最大差别在于栈是LIFO(后进先出)，而队列是FIFO，即先进先出。

队列的基本操作

- Enqueue()?——?在队列尾部插入元素
- Dequeue()?——移除队列头部的元素
-  isEmpty()——如果队列为空，则返回true
- Top()?——返回队列的第一个元素

面试中关于队列的常见问题

- 使用队列表示栈

- 对队列的前k个元素倒序

- 使用队列生成从1到n的二进制数

- #### 两个队列实现一个栈：

  思路：

  　　**将1、2、3依次入队列一， 然后最上面的3留在队列一，将下面的2、3入队列二，将3出队列一，此时队列一空了，然后把队列二中的所有数据入队列一；将最上面的2留在队列一，将下面的3入队列二。。。依次循环。**

## 树

树是使用了递归定义的数据结构，树的子树还是树，其结构如下图所示

![这里写图片描述](https://img-blog.csdn.net/20170222151857207?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzU2NDQyMzQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

- 度：结点拥有的子树数目，例如上图结点A的度为3，结点E的度为0
- 叶子或终端结点：度为0的结点（没有子树的结点）
- 树的度：各个结点中度的最大值
- 孩子：结点的子树的根，称为根的孩子
- 层次：根的层次为0，根的孩子为1，以此类推
- 深度：树中结点的最大层次，称为树的深度

### 二叉树

二叉树是一种每个结点至多只有两个子树（即二叉树的每个结点的度不大于2），并且二叉树的子树有左右之分，其次序不能任意颠倒。

#### 性质

- 在二叉树的第i层，至多有2^(i)个结点

- 深度为k的二叉树至多有：(2^k+1)-1个结点，其实这个结果就是一个等比数列的求和得到的。

- 对任意一颗二叉树，如果其叶子结点数量为：n0,度为2的结点数为：n2，则：n0=n2+1

  注释：这里对第三个性质做一个解释，首先我们都知道一个二叉树每个结点都是由度为0，1，2，三种情况，我们这里假设，二叉树有n个结点，其中度为1的结点数为：n1，于是由已知条件可知：n=n1+n0+n2;
  好，现在，我们在从另外一个角度想，我们二叉树有B条边，假设这些边都是从父亲结点指向它的孩子，那么我们会发现除了根结点外，其他结点都是有一天边的，所以：n=B+1,其中这些边都是由度为1和2的结点射出来的，所以：B=n1+2*n2,因此：n=n1+2*n2+1.所以，联立等式：n1+2*n2+1=n1+n0+n2,我们可以得到一个等式：n0=n2+1;

- 满二叉树定理：非空满二叉树树叶数目等于其分支节点数加1

- 满二叉树定理推论：一个非空二叉树的空子树数目等于其节点数加1

- 具有n个结点的完全二叉树的高度为：
  $$
\lceil log2(n+1) \rceil
  $$
，深度为
  $$
  \lceil log2(n+1)-1 \rceil
$$
  
  注释：首先我们先定义满二叉树：一颗深度为k且结点数为：（2^k）-1的二叉树，我们称为满二叉树，然后，我们对满二叉树进行编号，从根结点开始，从左往右，从上到下。然后就是可以定义一个完全二叉树：深度为k，结点数为n的二叉树，而且，每一个结点的位置都和深度为k的完全二叉树中编号为1到n的结点一一对应，我们称为完全二叉树。如下图所示：
  
  ![这里写图片描述](https://img-blog.csdn.net/20170222161837514?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzU2NDQyMzQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
  
  然后，我们现在就可以解释第四个性质了，假设我们的深度为k，由我们的完全二叉树的定义，我们可以知
  道：2^(k-1)-1< n <=(2^k)-1 即：2^(k-1)<=n<(2^k)，所以：k-1 < = [log2n] < k,因为k是整数，所以k=[log2n]+1，其中[log2n]+1是向下取整。
  
- 有N个结点的完全二叉树各结点如果用顺序方式存储，则结点之间有如下关系（0≤ i ≤ N-1）：

  　- 若i为结点编号则 如果i>0，则其父结点的编号为[（i-1）/2]，[]是往下取整的；
   
  - 如果2i+1 ≤ N-1，则其左儿子（即左子树的根结点）的编号为2i+1；否则无左儿子；
  
    如果2i+2 ≤ N-1，则其右儿子的结点编号为2i+2；否则无右儿子。

#### 遍历二叉树

所谓的遍历其实就是按照某种搜索路径，遍历树中的每个结点。我们都知道二叉树由三个基本的单元组成：根结点、左子树、右子树，所以遍历整个二叉树就是遍历二叉树的三个基本单元，根据随机组合的原理，可以产生6中遍历方案：DLR、LDR、LRD、RDL、RLD、LRD,另外，遍历的时候，一般要求先左后右的，所以我们只会选择前三种遍历方案。

- 先序遍历（DRL）
  （1）先访问根结点
  （2）先序遍历左子树
  （3）先序遍历右子树

- 中序遍历（LDR）
  （1）先中序遍历左子树
  （2）访问根结点
  （3）中序遍历右子树

- 后序遍历（LRD）
  （1）后序遍历左子树
  （2）后序遍历右子树
  （3）访问根结点

![这里写图片描述](https://img-blog.csdn.net/20170223160351319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzU2NDQyMzQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



## 图

图是一组以网络形式相互连接的节点。节点也称为顶点。 一对节点(x，y)称为边(edge)，表示顶点x连接到顶点y。边可以包含权重/成本，显示从顶点x到y所需的成本。

图的类型

- 无向图
- 有向图

在程序语言中，图可以用两种形式表示：

- 邻接矩阵（相邻矩阵）

  - 邻接[矩阵](https://baike.baidu.com/item/矩阵)（Adjacency Matrix）是表示顶点之间相邻关系的矩阵。设G=(V,E)是一个图，其中V={v1,v2,…,vn} [1] 。G的邻接矩阵是一个具有下列性质的n阶方阵：

    ①对[无向图](https://baike.baidu.com/item/无向图)而言，邻接矩阵一定是对称的，而且主对角线一定为零（在此仅讨论无向简单图），副对角线不一定为0，[有向图](https://baike.baidu.com/item/有向图)则不一定如此。

    ②在无向图中，任一顶点i的度为第i列（或第i行）所有非零元素的个数，在有向图中顶点i的出度为第i行所有非零元素的个数，而入度为第i列所有非零元素的个数。

    ③用邻接矩阵法表示图共需要n^2个空间，由于无向图的邻接矩阵一定具有[对称关系](https://baike.baidu.com/item/对称关系)，所以扣除对角线为零外，仅需要存储上三角形或下三角形的数据即可，因此仅需要n（n-1）/2个空间。

- 邻接表

  - 邻接表，存储方法跟树的孩子链表示法相类似，是一种顺序分配和链式分配相结合的[存储结构](https://baike.baidu.com/item/存储结构/350782)。如这个表头结点所对应的顶点存在相邻顶点，则把相邻顶点依次存放于表头结点所指向的单向链表中。

常见图遍历算法

- 广度优先搜索
- 深度优先搜索

面试中关于图的常见问题

- 实现广度和深度优先搜索
- 检查图是否为树
- 计算图的边数
- 找到两个顶点之间的最短路径
- Dijkstra
- Floyd

### Dijkstra

#### 定义

Dijkstra(迪杰斯特拉)算法是**单源**最短路径算法，用于计算**一个节点到其他所有节点**的最短路径。

##### 特点

以起始点为中心向外层层扩展，直到扩展到终点为止。

##### 基本思想

假设 G=(V,{E}) 是一个带权有向图，把图中顶点集合 V 分成两组，

- 第一组为**已求出**最短路径的顶点集合 S 及其路径长度（初始时 S 中只有一个源点，以后每求得一条最短路径 , 就加入到集合 S 中，直到全部顶点都加入到 S 中）
- 第二组为**未确定**最短路径的顶点集合 U 及其路径长度，按最短路径长度递增次序依次把 U 中的点加入 S 中。在加入的过程中，总保持从源点 v 到 S 中各顶点的最短路径长度不大于从源点 v 到 U 中任何顶点的最短路径长度。

此外，每个点对应一个距离，S 中点的路径长度就是从 v 到这个点的最短路径长度，U 中的点的路径长度，是从 v 到这个点由 S 中的顶点作为中间顶点的当前最短路径长度。

> 迪杰特斯拉算法不是一下子求出源点到其余各点的最短路径，而是一步步求出它们之间顶点的最短路径，过程中都是基于已经求出的最短路径的基础上，求得更远顶点的最短路径，最终得到结果。

##### 算法步骤

1. 初始时，S 只包含源点，即 S＝{v}，v 的距离为 0。U 包含除 v 外的其他顶点，即：U={其余顶点}，若 v 与 U 中顶点 u 有边，则 <u,v> 正常有权值，若 u 不是 v 的邻接点，则 <u,v> 权值为 ∞。
2. 从 U 中选取一个距离 v 最小的顶点 k，把 k加入 S 中（该选定的距离就是 v 到 k 的最短路径长度）。
3. 以 k 为新考虑的中间点，修改 U 中各顶点的距离；若从源点v 到顶点 u 的距离（经过顶点 k）比原来距离（不经过顶点k）短，则修改顶点 u 的距离值，修改后的距离值的顶点 k 的距离加上边上的权。
4. 重复步骤 2 和 3 直到所有顶点都包含在 S 中。

##### 算法实例

给出一个无向图：
![这里写图片描述](https://www.pianshen.com/images/172/920e98abd19b81e3b78148a49aad7cb4.png)
用Dijkstra算法找出以 v0 为起点的单源最短路径步骤如下：
![这里写图片描述](https://www.pianshen.com/images/812/61c70ef3ae23c1c1423b04e22b935324.png)

#### 相关代码

```python

import heapq
import math

def init_distance(graph, s):
    distance = {s: 0}
    for vertex in graph:
        if vertex != s:
            distance[vertex] = math.inf
    return distance


def dijkstra(graph, s):
    pqueue = []
    heapq.heappush(pqueue, (0, s))
    seen = set()
    parent = {s: None}
    distance = init_distance(graph, s)

    while len(pqueue) > 0:
        pair = heapq.heappop(pqueue)
        dist = pair[0]
        vertex = pair[1]
        seen.add(s)
        nodes = graph[vertex].keys()
        for w in nodes:
            if w not in seen:
                if dist + graph[vertex][w] < distance[w]:
                    heapq.heappush(pqueue, (dist + graph[vertex][w], w))
                    parent[w] = vertex
                    distance[w] = dist + graph[vertex][w]
    return parent, distance


if __name__ == '__main__':
    graph_dict = {
        "A": {"B": 5, "C": 1},
        "B": {"A": 5, "C": 2, "D": 1},
        "C": {"A": 1, "B": 2, "D": 4, "E": 8},
        "D": {"B": 1, "C": 4, "E": 3, "F": 6},
        "E": {"C": 8, "D": 3},
        "F": {"D": 6},
    }
    parent_dict, distance_dict = dijkstra(graph_dict, "A")
	print(parent_dict)
	print(distance_dict)
```

### Floyd

#### 简介

在计算机科学中，Floyd-Warshall算法是一种在具有正或负边缘权重（但没有负周期）的加权图中找到最短路径的算法。算法的单个执行将找到所有顶点对之间的最短路径的长度（加权）。 虽然它不返回路径本身的细节，但是可以通过对算法的简单修改来重建路径。 该算法的版本也可用于查找关系R的传递闭包，或（与Schulze投票系统相关）在加权图中所有顶点对之间的最宽路径。

Floyd-Warshall算法是[动态规划](https://baike.baidu.com/item/动态规划)的一个例子，并在1962年由Robert Floyd以其当前公认的形式出版。然而，它基本上与Bernard Roy在1959年先前发表的算法和1962年的Stephen Warshall中找到图形的传递闭包基本相同，并且与Kleene的算法密切相关 在1956年）用于将确定性[有限自动机](https://baike.baidu.com/item/有限自动机/8700995)转换为正则表达式。算法作为三个嵌套for循环的现代公式首先由Peter Ingerman在1962年描述。

该算法也称为Floyd算法，Roy-Warshall算法，Roy-Floyd算法或WFI算法。 [2] 

#### 核心思路

> ##### 路径矩阵
>
> 通过一个图的权值[矩阵](https://baike.baidu.com/item/矩阵)求出它的每两点间的[最短路径](https://baike.baidu.com/item/最短路径)矩阵。 [3] 
>
> 从图的带权[邻接矩阵](https://baike.baidu.com/item/邻接矩阵)A=[a(i,j)] n×n开始，[递归](https://baike.baidu.com/item/递归)地进行n次更新，即由矩阵D(0)=A，按一个公式，构造出矩阵D(1)；又用同样地公式由D(1)构造出D(2)；……；最后又用同样的公式由D(n-1)构造出矩阵D(n)。矩阵D(n)的i行j列元素便是i号顶点到j号顶点的最短路径长度，称D(n)为图的[距离矩阵](https://baike.baidu.com/item/距离矩阵)，同时还可引入一个后继节点矩阵path来记录两点间的最短路径。
>
> 采用松弛技术（[松弛操作](https://baike.baidu.com/item/松弛操作)），对在i和j之间的所有其他点进行一次松弛。所以时间复杂度为O(n^3);
>
> ##### 状态转移方程
>
> 其[状态转移方程](https://baike.baidu.com/item/状态转移方程)如下： map[i,j]:=min{map[i,k]+map[k,j],map[i,j]}；
>
> map[i,j]表示i到j的最短距离，K是穷举*i,j的*断点，map[n,n]初值应该为0，或者按照题目意思来做。
>
> 当然，如果这条路没有通的话，还必须特殊处理，比如没有map[i,k]这条路。

#### 算法过程

> 1，从任意一条单边路径开始。所有两点之间的距离是边的权，如果两点之间没有边相连，则权为无穷大。
>
> 2，对于每一对顶点 u 和 v，看看是否存在一个顶点 w 使得从 u 到 w 再到 v 比已知的路径更短。如果是更新它。
>
> 把图用邻接矩阵G表示出来，如果从Vi到Vj有路可达，则G[i][j]=d，d表示该路的长度；否则G[i][j]=无穷大。定义一个矩阵D用来记录所插入点的信息，D[i][j]表示从Vi到Vj需要经过的点，初始化D[i][j]=j。把各个顶点插入图中，比较插点后的距离与原来的距离，G[i][j] = min( G[i][j], G[i][k]+G[k][j] )，如果G[i][j]的值变小，则D[i][j]=k。在G中包含有两点之间最短道路的信息，而在D中则包含了最短通路径的信息。
>
> 比如，要寻找从V5到V1的路径。根据D，假如D(5,1)=3则说明从V5到V1经过V3，路径为{V5,V3,V1}，如果D(5,3)=3，说明V5与V3直接相连，如果D(3,1)=1，说明V3与V1直接相连。 

#### 相关代码

```java
public class Floyd {
    /**
     * 距离矩阵
     */
    public static int[][] distance;
    /**
     * 路径矩阵
     */
    public static int[][] path;

    public static void floyd(int[][] graph) {
        //初始化距离矩阵 distance
        distance = graph;
        //初始化路径
        path = new int[graph.length][graph.length];
        for (int i = 0; i < graph.length; i++) {
            for (int j = 0; j < graph[i].length; j++) {
                path[i][j] = j;
            }
        }
        //开始 Floyd 算法
        //每个点为中转
        for (int i = 0; i < graph.length; i++) {
            //所有入度
            for (int j = 0; j < graph.length; j++) {
                //所有出度
                for (int k = 0; k < graph[j].length; k++) {
                    //以每个点为「中转」，刷新所有出度和入度之间的距离
                    //例如 AB + BC < AC 就刷新距离
                    if (graph[j][i] != -1 && graph[i][k] != -1) {
                        int newDistance = graph[j][i] + graph[i][k];
                        if (newDistance < graph[j][k] || graph[j][k] == -1) {
                            //刷新距离
                            graph[j][k] = newDistance;
                            //刷新路径
                            path[j][k] = i;
                        }
                    }
                }
            }
        }
    }
    
    /**
     * 测试
     */
    public static void main(String[] args) {
        char[] vertices = new char[]{'A', 'B', 'C', 'D'};
        int[][] graph = new int[][]{
                {0, 2, -1, 6}
                , {2, 0, 3, 2}
                , {-1, 3, 0, 2}
                , {6, 2, 2, 0}};
        floyd(graph);
        System.out.println("====distance====");
        for (int[] ints : distance) {
            for (int anInt : ints) {
                System.out.print(anInt + " ");
            }
            System.out.println();
        }
        System.out.println("====path====");
        for (int[] ints : path) {
            for (int anInt : ints) {
                System.out.print(anInt + " ");
            }
            System.out.println();
        }
    }

}
```



## 哈希表

哈希法(Hashing)是一个用于唯一标识对象并将每个对象存储在一些预先计算的唯一索引(称为“键(key)”)中的过程。因此，对象以键值对的形式存储，这些键值对的集合被称为“字典”。可以使用键搜索每个对象。基于哈希法有很多不同的数据结构，但最常用的数据结构是哈希表。哈希表通常使用数组实现/链表也有。

##### 碰撞

​	好的Hash算法可以出计算几乎出独一无二的HashCode，如果出现了重复的hashCode，就称作碰撞;

就算是MD5这样优秀的算法也会发生碰撞，即两个不同的key也有可能生成相同的MD5。

**谈一下HashMap的底层原理是什么？**

​	基于hashing的原理，jdk8后采用数组+链表+红黑树的数据结构。我们通过put和get存储和获取对象。当我们给put()方法传递键和值时，先对键做一个hashCode()的计算来得到它在bucket数组中的位置来存储Entry对象。当获取对象时，通过get获取到bucket的位置，再通过键对象的equals()方法找到正确的键值对，然后在返回值对象。

##### “你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？”

- HashMap 是一个散列桶（数组和链表），它存储的内容是键值对 key-value 映射
  HashMap 采用了数组和链表的数据结构，能在查询和修改方便继承了数组的线性查找和链表的寻址修改
  HashMap 是非 synchronized，所以 HashMap 很快
  HashMap 可以接受 null 键和值，而 Hashtable 则不能（原因就是 equlas() 方法需要对象，因为 HashMap 是后出的 API 经过处理才可以）

- 以下是具体的 put 过程（JDK1.8）

  对 Key 求 Hash 值，然后再计算下标
  如果没有碰撞，直接放入桶中（碰撞的意思是计算得到的 Hash 值相同，需要放到同一个 bucket 中）
  如果碰撞了，以链表的方式链接到后面
  如果链表长度超过阀值（TREEIFY THRESHOLD==8），就把链表转成红黑树，链表长度低于6，就把红黑树转回链表
  如果节点已经存在就替换旧值
  如果桶满了（容量16*加载因子0.75），就需要 resize（扩容2倍后重排）
  以下是具体 get 过程

  考虑特殊情况：如果两个键的 hashcode 相同，你如何获取值对象？

  当我们调用 get() 方法，HashMap 会使用键对象的 hashcode 找到 bucket 位置，找到 bucket 位置之后，会调用 keys.equals() 方法去找到链表中正确的节点，最终找到要找的值对象。

**谈一下hashMap中put是如何实现的？**

1.计算关于key的hashcode值（与Key.hashCode的高16位做异或运算）

2.如果散列表为空时，调用resize()初始化散列表

3.如果没有发生碰撞，直接添加元素到散列表中去

4.如果发生了碰撞(hashCode值相同)，进行三种判断

  4.1:若key地址相同或者equals后内容相同，则替换旧值

  4.2:如果是红黑树结构，就调用树的插入方法

  4.3：链表结构，循环遍历直到链表中某个节点为空，尾插法进行插入，插入之后判断链表个数是否到达变成红黑树的阙值8；也可以遍历到有节点与插入元素的哈希值和内容相同，进行覆盖。

5.如果桶满了大于阀值，则resize进行扩容



**谈一下HashMap中hash函数是怎么实现的？还有哪些hash函数的实现方式？**

对key的hashCode做hash操作，与高16位做异或运算。还有平方取中法，除留余数法，伪随机数法

**解决哈希冲突的方法**

哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。

1） 线性探测法

2） 平方探测法

3） 伪随机序列法

4） 拉链法



**谈一下当两个对象的hashCode相等时会怎么样？**

​	会产生哈希碰撞，若key值相同则替换旧值，不然链接到链表后面，链表长度超过阙值8就转为红黑树存储



**HashMap和HashTable的区别**

相同点：都是存储key-value键值对的

不同点：

- HashMap允许Key-value为null，hashTable不允许；
- hashMap没有考虑同步，是线程不安全的。hashTable是线程安全的，给api套上了一层synchronized修饰;
- HashMap继承于AbstractMap类，hashTable继承与Dictionary类。
- 迭代器(Iterator)。HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException。
- 容量的初始值和增加方式都不一样：HashMap默认的容量大小是16；增加容量时，每次将容量变为"原始容量x2"。Hashtable默认的容量大小是11；增加容量时，每次将容量变为"原始容量x2 + 1"；
- 添加key-value时的hash值算法不同：HashMap添加元素时，是使用自定义的哈希算法。Hashtable没有自定义哈希算法，而直接采用的key的hashCode()。

**传统hashMap的缺点(为什么引入红黑树？)：**

JDK 1.8 以前 HashMap 的实现是 数组+链表，即使哈希函数取得再好，也很难达到元素百分百均匀分布。当 HashMap 中有大量的元素都存放到同一个桶中时，这个桶下有一条长长的链表，这个时候 HashMap 就相当于一个单链表，假如单链表有 n 个元素，遍历的时间复杂度就是 O(n)，完全失去了它的优势。针对这种情况，JDK 1.8 中引入了 红黑树（查找时间复杂度为 O(logn)）来优化这个问题。



##### 扩容时导致死循环

​	这是最常遇到的情况，也是面试经常被问及的考题。但说实话，这个多线程环境下导致的死循环问题，并不是那么容易解释清楚，因为这里已经深入到了扩容的细节。这里尽可能简单的描述死循环的产生过程。

​	另外，只有JDK7及以前的版本会存在死循环现象，在JDK8中，resize()方式已经做了调整，使用两队链表，且都是使用的尾插法，及时多线程下，也顶多是从头结点再做一次尾插法，不会造成死循环。而JDK7能造成死循环，就是因为resize()时使用了头插法，将原本的顺序做了反转，才留下了死循环的机会。

散列数据构的性能取决于以下三个因素

- 哈希函数
- 哈希表的大小
- 碰撞处理方法

面试中关于哈希结构的常见问题

- 在数组中查找对称键值对
- 追踪遍历的完整路径
- 查找数组是否是另一个数组的子集
- 检查给定的数组是否不相交

## Huffman树与Huffman编码

### Huffman树

Huffman树是一种特殊结构的二叉树，由Huffman树设计的二进制前缀编码，也称为Huffman编码在通信领域有着广泛的应用。在word2vec模型中，在构建层次Softmax的过程中，也使用到了Huffman树的知识。

在通信中，需要将传输的文字转换成二进制的字符串，假设传输的报文为：“AFTERDATAEARAREARTAREA”，现在需要对该报文进行编码。

**Huffman Tree，中文名是哈夫曼树或霍夫曼树，它是最优二叉树。**

**定义**：给定n个权值作为n个叶子结点，构造一棵二叉树，若**树的带权路径长度达到最小**，则这棵树被称为哈夫曼树。这个定义里面涉及到了几个陌生的概念，下面就是一颗哈夫曼树，我们来看图解答。

[![img](https://github.com/wangkuiwu/datastructs_and_algorithm/blob/master/pictures/tree/huffman/01.jpg?raw=true)](https://github.com/wangkuiwu/datastructs_and_algorithm/blob/master/pictures/tree/huffman/01.jpg?raw=true)

(01) 路径和路径长度

> **定义**：在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。通路中分支的数目称为路径长度。若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1。 **例子**：100和80的路径长度是1，50和30的路径长度是2，20和10的路径长度是3。

(02) 结点的权及带权路径长度

> **定义**：若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。结点的带权路径长度为：从根结点到该结点之间的路径长度与该结点的权的乘积。 **例子**：节点20的路径长度是3，它的带权路径长度= 路径长度 * 权 = 3 * 20 = 60。

(03) 树的带权路径长度

> **定义**：树的带权路径长度规定为所有叶子结点的带权路径长度之和，记为WPL。 **例子**：示例中，树的WPL= 1**100 + 2\*50* + 3**20 + 3**10 = 100 + 100 + 60 + 30 = 290。

比较下面两棵树

[![img](https://github.com/wangkuiwu/datastructs_and_algorithm/blob/master/pictures/tree/huffman/02.jpg?raw=true)](https://github.com/wangkuiwu/datastructs_and_algorithm/blob/master/pictures/tree/huffman/02.jpg?raw=true)

上面的两棵树都是以{10, 20, 50, 100}为叶子节点的树。

> 左边的树WPL=2*10 + 2*20 + 2*50 + 2*100 = 360 右边的树WPL=350

左边的树WPL > 右边的树的WPL。你也可以计算除上面两种示例之外的情况，但实际上右边的树就是{10,20,50,100}对应的哈夫曼树。至此，应该堆哈夫曼树的概念有了一定的了解了，下面看看如何去构造一棵哈夫曼树。

#### **哈夫曼树构造的图文解析**

假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 w1、w2、…、wn，哈夫曼树的构造规则为：

> **1**. 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点)； 
>
> **2**. 在森林中选出根结点的权值最小的两棵树进行合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和； 
>
> **3**. 从森林中删除选取的两棵树，并将新树加入森林； 
>
> **4**. 重复(02)、(03)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。

以{5,6,7,8,15}为例，来构造一棵哈夫曼树。

[![img](https://github.com/wangkuiwu/datastructs_and_algorithm/blob/master/pictures/tree/huffman/03.jpg?raw=true)](https://github.com/wangkuiwu/datastructs_and_algorithm/blob/master/pictures/tree/huffman/03.jpg?raw=true)

**第1步**：创建森林，森林包括5棵树，这5棵树的权值分别是5,6,7,8,15。 

**第2步**：在森林中，选择根节点权值最小的两棵树(5和6)来进行合并，将它们作为一颗新树的左右孩子(谁左谁右无关紧要，这里，我们选择较小的作为左孩子)，并且新树的权值是左右孩子的权值之和。即，新树的权值是11。 然后，将"树5"和"树6"从森林中删除，并将新的树(树11)添加到森林中。 

**第3步**：在森林中，选择根节点权值最小的两棵树(7和8)来进行合并。得到的新树的权值是15。 然后，将"树7"和"树8"从森林中删除，并将新的树(树15)添加到森林中。 

**第4步**：在森林中，选择根节点权值最小的两棵树(11和15)来进行合并。得到的新树的权值是26。 然后，将"树11"和"树15"从森林中删除，并将新的树(树26)添加到森林中。 

**第5步**：在森林中，选择根节点权值最小的两棵树(15和26)来进行合并。得到的新树的权值是41。 然后，将"树15"和"树26"从森林中删除，并将新的树(树41)添加到森林中。 此时，森林中只有一棵树(树41)。这棵树就是我们需要的哈夫曼树！

### 哈夫曼编码

哈夫曼树的应用很广，哈夫曼编码就是其在电讯通信中的应用之一。广泛地用于数据文件压缩的十分有效的编码方法。其压缩率通常在20%～90%之间。在电讯通信业务中，通常用二进制编码来表示字母或其他字符，并用这样的编码来表示字符序列。 

例：如果需传送的电文为 ‘ABACCDA’，它只用到四种字符，用两位二进制编码便可分辨。假设 A, B, C, D 的编码分别为 00, 01,10, 11，则上述电文便为 ‘00010010101100’（共 14 位），译码员按两位进行分组译码，便可恢复原来的电文。

能否使编码总长度更短呢？

实际应用中各字符的出现频度不相同，用短（长）编码表示频率大（小）的字符，使得编码序列的总长度最小，使所需总空间量最少

**数据的最小冗余编码问题**

在上例中，若假设 A, B, C, D 的编码分别为 0，00，1，01，则电文 ‘ABACCDA’ 便为 ‘000011010’（共 9 位），但此编码存在多义性：可译为： ‘BBCCDA’、‘ABACCDA’、‘AAAACCACA’ 等。

**译码的惟一性问题**

要求**任一字符的编码都不能是另一字符编码的前缀**，这种编码称为前缀编码（其实是非前缀码）。 在编码过程要考虑两个问题，数据的最小冗余编码问题，译码的惟一性问题，利用最优二叉树可以很好地解决上述两个问题

用二叉树设计二进制前缀编码

以电文中的字符作为叶子结点构造二叉树。然后将二叉树中结点引向其左孩子的分支标 ‘0’，引向其右孩子的分支标 ‘1’； 每个字符的编码即为从根到每个叶子的路径上得到的 0, 1 序列。如此得到的即为二进制前缀编码。

 ![img](https://images0.cnblogs.com/blog2015/682679/201504/071113188834431.png)

编码： A：0， C：10，B：110，D：111 

 

任意一个叶子结点都不可能在其它叶子结点的路径中。

 

用哈夫曼树设计总长最短的二进制前缀编码

假设各个字符在电文中出现的次数（或频率）为 wi ，其编码长度为 li，电文中只有 n 种字符，则电文编码总长为：![img](https://images0.cnblogs.com/blog2015/682679/201504/071118335406768.png)

 

设计电文总长最短的编码，设计哈夫曼树（以 n 种字符出现的频率作权），

由哈夫曼树得到的二进制前缀编码称为哈夫曼编码  

例：如果需传送的电文为 ‘ABACCDA’，即：A, B, C, D 

的频率（即权值）分别为 0.43, 0.14, 0.29, 0.14，试构造哈夫曼编码。

![img](https://images0.cnblogs.com/blog2015/682679/201504/071119163834879.png)

 

编码： A：0， C：10， B：110， D：111 。电文 ‘ABACCDA’ 便为 ‘0110010101110’（共 13 位）。

 

例：如果需传送的电文为 ‘ABCACCDAEAE’，即：A, B, C, D, E 的频率（即权值）分别为0.36, 0.1, 0.27, 0.1, 0.18，试构造哈夫曼编码。

![img](https://images0.cnblogs.com/blog2015/682679/201504/071119483365384.png)

 

编码： A：11，C：10，E：00，B：010，D：011 ，则电文 ‘ABCACCDAEAE’ 便为 ‘110101011101001111001100’（共 24 位，比 33 位短）。

 

译码

从哈夫曼树根开始，对待译码电文逐位取码。若编码是“0”，则向左走；若编码是“1”，则向右走，一旦到达叶子结点，则译出一个字符；再重新从根出发，直到电文结束。

![img](https://images0.cnblogs.com/blog2015/682679/201504/071120393525832.png)

电文为 “1101000” ，译文只能是“CAT”



## 字典树

又称单词查找树，[Trie树](https://baike.baidu.com/item/Trie树)，是一种[树形结构](https://baike.baidu.com/item/树形结构/9663807)，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的[字符](https://baike.baidu.com/item/字符)串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。

## ![img](https://images2015.cnblogs.com/blog/713721/201606/713721-20160624160557531-261335182.png)

```
class TrieNode // 字典树节点
    {
        private int num;// 有多少单词通过这个节点,即由根至该节点组成的字符串模式出现的次数
        private TrieNode[] son;// 所有的儿子节点
        private boolean isEnd;// 是不是最后一个节点
        private char val;// 节点的值

        TrieNode()
        {
            num = 1;
            son = new TrieNode[SIZE];
            isEnd = false;
        }
        // 建立字典树
    public void insert(String str) // 在字典树中插入一个单词
    {
        if (str == null || str.length() == 0)
        {
            return;
        }
        TrieNode node = root;
        char[] letters = str.toCharArray();//将目标单词转换为字符数组
        for (int i = 0, len = str.length(); i < len; i++)
        {
            int pos = letters[i] - 'a';
            if (node.son[pos] == null)  //如果当前节点的儿子节点中没有该字符，则构建一个TrieNode并复值该字符
            {
                node.son[pos] = new TrieNode();
                node.son[pos].val = letters[i];
            } 
            else   //如果已经存在，则将由根至该儿子节点组成的字符串模式出现的次数+1
            {
                node.son[pos].num++;
            }
            node = node.son[pos];
        }
        node.isEnd = true;
    }
    // 在字典树中查找一个完全匹配的单词.
    public boolean has(String str)
    {
        if(str==null||str.length()==0)
        {
            return false;
        }
        TrieNode node=root;
        char[]letters=str.toCharArray();
        for(int i=0,len=str.length(); i<len; i++)
        {
            int pos=letters[i]-'a';
            if(node.son[pos]!=null)
            {
                node=node.son[pos];
            }
            else
            {
                return false;
            }
        }
        //走到这一步，表明可能完全匹配，也可能部分匹配，如果最后一个字符节点为末端节点，则是完全匹配，否则是部分匹配
        return node.isEnd;
    }

    }
```



## 二叉搜索树/二叉排序树/BST

二叉查找树（BST：Binary Search Tree）是一种特殊的二叉树，它改善了二叉树节点查找的效率。二叉查找树有以下性质：

（1）若左子树不空，则左子树上所有节点的值均小于它的根节点的值

（2）若右子树不空，则右子树上所有节点的值均大于它的根节点的值

（3）左、右子树也分别为二叉排序树

（4）没有键值相等的节点

对于 BST 查找算法来说，其十分依赖于树中节点的拓扑结构，也就是节点间的布局关系，当 BST 树中的节点以扇形结构散开时，对它的插入、删除和查找操作最优的情况下可以达到亚线性的运行时间 O(log2n)，

因为当在 BST 中查找一个节点时，每一步比较操作后都会将节点的数量减少一半。尽管如此，如果拓扑结构像下图中的样子时，运行时间就会退减到线性时间 O(n)。因为每一步比较操作后还是需要逐个比较其余的节点，

也就是说，在这种情况下，在 BST 中查找节点与在数组（Array）中查找就基本类似了。

因此，**BST 算法查找时间依赖于树的拓扑结构。最佳情况是 O(log­2n)，而最坏情况是 O(n)**

![img](https://img2018.cnblogs.com/blog/1590962/201908/1590962-20190804152452542-181454516.gif)![img](https://img2018.cnblogs.com/blog/1590962/201908/1590962-20190804153005821-2035926941.gif)

#### 构造复杂度

二叉搜索树的构造过程，也就是将节点不断插入到树中适当位置的过程。该操作过程，与查询节点元素的操作基本相同，不同之处在于：

- 查询节点过程是，比较元素值是否相等，相等则返回，不相等则判断大小情况，迭代查询左、右子树，直到找到相等的元素，或子节点为空，返回节点不存在
- 插入节点的过程是，比较元素值是否相等，相等则返回，表示已存在，不相等则判断大小情况，迭代查询左、右子树，直到找到相等的元素，或子节点为空，则将节点插入该空节点位置。

由此可知，单个节点的构造复杂度和查询复杂度相同，为 ![O(log_2 n)](https://math.jianshu.com/math?formula=O(log_2%20n))~![O(n)](https://math.jianshu.com/math?formula=O(n))。

### 删除复杂度

二叉搜索树的节点删除包括两个过程，查找和删除。查询的过程和查询复杂度已知，这里说明一下删除节点的过程。

##### 节点的删除有以下三种情况：

1. 待删除节点度为零；
2. 待删除节点度为一；
3. 待删除节点度为二。

第一种情况如下图 s_1 所示，待删除节点值为 “6”，该节点无子树，删除后并不影响二叉搜索树的结构特性，可以直接删除。即二叉搜索树中待删除节点度为零时，该节点为叶子节点，可以直接删除；

![img](https:////upload-images.jianshu.io/upload_images/9738807-3198aaba4a6ddbc6.png?imageMogr2/auto-orient/strip|imageView2/2/w/169/format/webp)

s_1

![img](https:////upload-images.jianshu.io/upload_images/9738807-fc4a12581b6c114a.png?imageMogr2/auto-orient/strip|imageView2/2/w/173/format/webp)

s_1'

第二种情况如下图 s_2 所示，待删除节点值为 “7”，该节点有一个左子树，删除节点后，为了维持二叉搜索树结构特性，需要将左子树“上移”到删除的节点位置上。即二叉搜索树中待删除的节点度为一时，可以将待删除节点的左子树或右子树“上移”到删除节点位置上，以此来满足二叉搜索树的结构特性。

![img](https:////upload-images.jianshu.io/upload_images/9738807-cbf680f5701e2644.png?imageMogr2/auto-orient/strip|imageView2/2/w/169/format/webp)

s_2

![img](https:////upload-images.jianshu.io/upload_images/9738807-668ce378c9d9e766.png?imageMogr2/auto-orient/strip|imageView2/2/w/173/format/webp)

s_2'

第三种情况如下图 s_3 所示，待删除节点值为 “9”，该节点既有左子树，也有右子树，删除节点后，为了维持二叉搜索树的结构特性，需要从其左子树中选出一个最大值的节点，“上移”到删除的节点位置上。即二叉搜索树中待删除节点的度为二时，可以将待删除节点的左子树中的最大值节点“移动”到删除节点位置上，以此来满足二叉搜索树的结构特性。

> 其实在真实的实现代码中，该情况下的实际节点删除操作是：
>  1.查找出左子树中的最大值节点 ![Node_{max}](https://math.jianshu.com/math?formula=Node_%7Bmax%7D)
>  2.替换待删除节点 ![node](https://math.jianshu.com/math?formula=node) 的值为 ![Node_{max}](https://math.jianshu.com/math?formula=Node_%7Bmax%7D) 的值
>  3.删除 ![Node_{max}](https://math.jianshu.com/math?formula=Node_%7Bmax%7D) 节点
>  因为 ![Node_{max}](https://math.jianshu.com/math?formula=Node_%7Bmax%7D) 作为左子树的最大值节点，所以节点的度一定是 0 或 1，所以删除节点的情况就转移为以上两种情况。

![img](https:////upload-images.jianshu.io/upload_images/9738807-6304a0221a05d3c7.png?imageMogr2/auto-orient/strip|imageView2/2/w/327/format/webp)

s_3

![img](https:////upload-images.jianshu.io/upload_images/9738807-28365e209d68b362.png?imageMogr2/auto-orient/strip|imageView2/2/w/327/format/webp)

s_3'

之前提到二叉搜索树中节点的删除操作，包括查询和删除两个过程，这里称删除节点后，维持二叉搜索树结构特性的操作为“稳定结构”操作，观察以上三种情况可知：

- 前两种情况下，删除节点后，“稳定结构”操作的复杂度都是常数级别，即整个的节点删除操作复杂度为 ![O(log_2 n)](https://math.jianshu.com/math?formula=O(log_2%20n))~![O(n)](https://math.jianshu.com/math?formula=O(n))；
- 第三种情况下，设删除的节点为 ![p](https://math.jianshu.com/math?formula=p)，“稳定结构”操作需要查找 ![p](https://math.jianshu.com/math?formula=p) 节点左子树中的最大值，也就是左子树中最“右”的叶子结点，即“稳定结构”操作其实也是一种内部的查询操作，所以整个的节点删除操作其实就是两个层次的查询操作，复杂度同为 ![O(log_2 n)](https://math.jianshu.com/math?formula=O(log_2%20n))~![O(n)](https://math.jianshu.com/math?formula=O(n))；

#### 性能分析

由以上查询复杂度、构造复杂度和删除复杂度的分析可知，三种操作的时间复杂度皆为 ![O(log_2 n)](https://math.jianshu.com/math?formula=O(log_2%20n))~![O(n)](https://math.jianshu.com/math?formula=O(n))。下面分析线性结构的三种操作复杂度，以二分法为例：

- 查询复杂度，时间复杂度为 ![O(log_2 n)](https://math.jianshu.com/math?formula=O(log_2%20n))，优于二叉搜索树；
- 元素的插入操作包括两个步骤，查询和插入。查询的复杂度已知，插入后调整元素位置的复杂度为 ![O(n)](https://math.jianshu.com/math?formula=O(n))，即单个元素的构造复杂度为：![O(n)](https://math.jianshu.com/math?formula=O(n))
- 删除操作也包括两个步骤，查询和删除，查询的复杂度已知，删除后调整元素位置的复杂度为 ![O(n)](https://math.jianshu.com/math?formula=O(n))，即单个元素的删除复杂度为：![O(n)](https://math.jianshu.com/math?formula=O(n))

由此可知，二叉搜索树相对于线性结构，在构造复杂度和删除复杂度方面占优；在查询复杂度方面，二叉搜索树可能存在类似于斜树，每层上只有一个节点的情况，该情况下查询复杂度不占优势。

#### 代码附录

> python版本：3.7，树中的遍历、节点插入和删除操作使用的是递归形式

- 树节点定义

```ruby
# tree node definition
class Node(object):
    def __init__(self, value, lchild=None, rchild=None):
        self.value = value
        self.lchild = lchild
        self.rchild = rchild
```

- 树定义

```ruby
# tree definition
class Tree(object):
    def __init__(self, root=None):
        self.root = root

    # node in-order traversal(LDR)
    def traversal(self):
        traversal(self.root)

    # insert node
    def insert(self, value):
        self.root = insert(self.root, value)

    # delete node
    def delete(self, value):
        self.root = delete(self.root, value)
```

- 模块中对树结构中的函数进行实现

```csharp
# node in-order traversal(LDR)
def traversal(node):
    if not node:
        return
    traversal(node.lchild)
    print(node.value,end=' ')
    traversal(node.rchild)

# insert node
def insert(root, value):
    if not root:
        return Node(value)
    if value < root.value:
        root.lchild = insert(root.lchild, value)
    elif value > root.value:
        root.rchild = insert(root.rchild, value)
    return root

# delete node
def delete(root, value):
    if not root:
        return None
    if value < root.value:
        root.lchild = delete(root.lchild, value)
    elif value > root.value:
        root.rchild = delete(root.rchild, value)
    else:
        if root.lchild and root.rchild:  # degree of the node is 2
            target = root.lchild  # find the maximum node of the left subtree
            while target.rchild:
                target = target.rchild
            root = delete(root, target.value)
            root.value = target.value
        else:  # degree of the node is [0|1]
            root = root.lchild if root.lchild else root.rchild
    return root
```

- 测试代码与输出

```go
if __name__ == '__main__':
    arr = [5, 3, 4, 0, 2, 1, 8, 6, 9, 7]
    T = Tree()
    for i in arr:
        T.insert(i)
    print('BST in-order traversal------------------')
    T.traversal()
    print('\ndelete test------------------')
    for i in arr[::-1]:
        print('after delete',i,end=',BST in-order is = ')
        T.delete(i)
        T.traversal()
        print()
```

输出结果为：

```cpp
BST in-order traversal------------------
0 1 2 3 4 5 6 7 8 9 
delete test------------------
after delete 7,BST in-order is = 0 1 2 3 4 5 6 8 9 
after delete 9,BST in-order is = 0 1 2 3 4 5 6 8 
after delete 6,BST in-order is = 0 1 2 3 4 5 8 
after delete 8,BST in-order is = 0 1 2 3 4 5 
after delete 1,BST in-order is = 0 2 3 4 5 
after delete 2,BST in-order is = 0 3 4 5 
after delete 0,BST in-order is = 3 4 5 
after delete 4,BST in-order is = 3 5 
after delete 3,BST in-order is = 5 
after delete 5,BST in-order is = 
```





## AVL树/自平衡二叉搜索树

 平衡二叉搜索树（Self-balancing binary search tree）又被称为AVL树（有别于AVL算法），且具有以下性质：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408203256251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

平衡因子
      某结点的左子树与右子树的高度(深度)差即为该结点的平衡因子（BF,Balance Factor）。平衡二叉树上所有结点的平衡因子只可能是 -1，0 或 1。如果某一结点的平衡因子绝对值大于1则说明此树不是平衡二叉树。为了方便计算每一结点的平衡因子我们可以为每个节点赋予height这一属性，表示此节点的高度。

#### LL（右旋）

   LL的意思是向左子树（L）的左孩子（L）中插入新节点后导致不平衡，这种情况下需要右旋操作，而不是说LL的意思是右旋，后面的也是一样。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408210355599.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408211619425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)



#### LL

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408214243812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408214353545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

#### LR

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408215652458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408220207905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

第三个图中x和z反了，失误

#### RL

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408215302630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190408215508810.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1MzQzNTU3,size_16,color_FFFFFF,t_70)

第二个图中y的左孩子为T1，第三个图中x和z反了，孩子也错了，应该是从左至右T1，T2，T3，T4，失误。。。

#### 删除节点

   在删除AVL树节点前需要知道二分搜索树的节点删除操作[【点此学习吧！】](https://blog.csdn.net/qq_25343557/article/details/84330095#t7)，和二分搜索树删除节点不同的是我们删除AVL树的节点后需要进行平衡的维护操作。



## 红黑树

**1.stl中的set底层用的什么数据结构？**

红黑树

**2.红黑树的数据结构怎么定义？**

 `enum Color  
{  
          RED = 0,  
          BLACK = 1  
};`  

`struct RBTreeNode  
{  
           struct RBTreeNode*left, *right, *parent;  
           int   key;  
           int data;  
           Color color;  
};`  

**3.红黑树有哪些性质？**

一般的，红黑树，满足以下性质，即只有满足以下全部性质的树，我们才称之为红黑树：
1）每个结点要么是红的，要么是黑的。
2）根结点是黑的。
3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。
4）如果一个结点是红的，那么它的俩个儿子都是黑的。
5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。

**4.红黑树的各种操作的时间复杂度是多少？**

能保证在最坏情况下，基本的动态几何操作的时间均为O（lgn）

 

**5.红黑树相比于BST和AVL树有什么优点？**

红黑树是牺牲了严格的高度平衡的优越条件为代价，它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。红黑树能够以O(log2 n)的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。当然，还有一些更好的，但实现起来更复杂的数据结构能够做到一步旋转之内达到平衡，但红黑树能够给我们一个比较“便宜”的解决方案。

相比于BST，因为红黑树可以能确保树的最长路径不大于两倍的最短路径的长度，所以可以看出它的查找效果是有最低保证的。在最坏的情况下也可以保证O(logN)的，这是要好于二叉查找树的。因为二叉查找树最坏情况可以让查找达到O(N)。

红黑树的算法时间复杂度和AVL相同，但统计性能比AVL树更高，所以在插入和删除中所做的后期维护操作肯定会比红黑树要耗时好多，但是他们的查找效率都是O(logN)，所以红黑树应用还是高于AVL树的. 实际上插入 AVL 树和红黑树的速度取决于你所插入的数据.如果你的数据分布较好,则比较宜于采用 AVL树(例如随机产生系列数),但是如果你想处理比较杂乱的情况,则红黑树是比较快的

 

**6.红黑树相对于哈希表，在选择使用的时候有什么依据？**

权衡三个因素: 查找速度, 数据量, 内存使用，可扩展性。
　　总体来说，hash查找速度会比map快，而且查找速度基本和数据量大小无关，属于常数级别;而map的查找速度是log(n)级别。并不一定常数就比log(n) 小，hash还有hash函数的耗时，明白了吧，如果你考虑效率，特别是在元素达到一定数量级时，考虑考虑hash。但若你对内存使用特别严格， 希望程序尽可能少消耗内存，那么一定要小心，hash可能会让你陷入尴尬，特别是当你的hash对象特别多时，你就更无法控制了，而且 hash的构造速度较慢。

红黑树并不适应所有应用树的领域。如果数据基本上是静态的，那么让他们待在他们能够插入，并且不影响平衡的地方会具有更好的性能。如果数据完全是静态的，例如，做一个哈希表，性能可能会更好一些。

在实际的系统中，例如，需要使用动态规则的防火墙系统，使用红黑树而不是散列表被实践证明具有更好的伸缩性。Linux内核在管理vm_area_struct时就是采用了红黑树来维护内存块的。

红黑树通过扩展节点域可以在不改变时间复杂度的情况下得到结点的秩。





## B树/B+树

#### B树

B树就是B-树。它是一颗多路平衡查找树。二叉树我想大家都不陌生，其实，B树和后面讲到的B+树也是从最简单的二叉树变换而来的，并没有什么神秘的地方，下面我们来看看B树的定义。

- 每个节点最多有m-1个**关键字**（可以存有的键值对）。
- 根节点最少可以只有1个**关键字**。
- 非根节点至少有m/2个**关键字**。
- 每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。
- 所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。
- 每个节点都存有索引和数据，也就是对应的key和value。

所以，根节点的**关键字**数量范围：`1 <= k <= m-1`，非根节点的**关键字**数量范围：`m/2 <= k <= m-1`。

另外，我们需要注意一个概念，描述一颗B树时需要指定它的阶数，阶数表示了一个节点最多有多少个孩子节点，一般用字母m表示阶数。

我们再举个例子来说明一下上面的概念，比如这里有一个5阶的B树，根节点数量范围：1 <= k <= 4，非根节点数量范围：2 <= k <= 4。

下面，我们通过一个插入的例子，讲解一下B树的插入过程，接着，再讲解一下删除关键字的过程。



#### B树插入

插入的时候，我们需要记住一个规则：**判断当前结点key的个数是否小于等于m-1，如果满足，直接插入即可，如果不满足，将节点的中间的key将这个节点分为左右两部分，中间的节点放到父节点中即可。**

例子：在5阶B树中，结点最多有4个key,最少有2个key（注意：下面的节点统一用一个节点表示key和value）。

- 插入18，70，50,40

![img](https://oscimg.oschina.net/oscnet/eb191e52c4af046dc6d858c793c8ddf3c8e.jpg)

- 插入22

![img](https://oscimg.oschina.net/oscnet/0c6e169e37ff9643c46c72922f42bcb5d46.jpg)

插入22时，发现这个节点的关键字已经大于4了，所以需要进行分裂，分裂的规则在上面已经讲了，分裂之后，如下。

![img](https://oscimg.oschina.net/oscnet/1377e97a1160e07ffa600c0d8cba7cadf1e.jpg)

- 接着插入23，25，39

![img](https://oscimg.oschina.net/oscnet/03e1e510bcd8672a98e1a67dd60a91d3aea.jpg)

分裂，得到下面的。

![img](https://oscimg.oschina.net/oscnet/1155825270844bbe53c9f2701395c3fa9af.jpg)

更过的插入的过程就不多介绍了，相信有这个例子你已经知道怎么进行插入操作了。

#### B树的删除操作

B树的删除操作相对于插入操作是相对复杂一些的，但是，你知道记住几种情况，一样可以很轻松的掌握的。

- 现在有一个初始状态是下面这样的B树，然后进行删除操作。

![img](https://oscimg.oschina.net/oscnet/261678b789a5f4dac373093919ea6a41b8a.jpg)

- 删除15，这种情况是删除叶子节点的元素，如果删除之后，节点数还是大于`m/2`，这种情况只要直接删除即可。

![img](https://oscimg.oschina.net/oscnet/0ed340c43b270b4a7932d7db15ebf0acc26.jpg)

![img](https://oscimg.oschina.net/oscnet/11e2970a52f2b9c73b2a30922b623d4e380.jpg)

- 接着，我们把22删除，这种情况的规则：22是非叶子节点，**对于非叶子节点的删除，我们需要用后继key（元素）覆盖要删除的key，然后在后继key所在的子支中删除该后继key**。对于删除22，需要将后继元素24移到被删除的22所在的节点。

![img](https://oscimg.oschina.net/oscnet/6343b9be4ff09d04096e9eac1d500ba0e9d.jpg)

![img](https://oscimg.oschina.net/oscnet/c60eb3ba1f5fac64515eccfc03192f40fdb.jpg)

此时发现26所在的节点只有一个元素，小于2个（m/2），这个节点不符合要求，这时候的规则（向兄弟节点借元素）：**如果删除叶子节点，如果删除元素后元素个数少于（m/2），并且它的兄弟节点的元素大于（m/2），也就是说兄弟节点的元素比最少值m/2还多，将先将父节点的元素移到该节点，然后将兄弟节点的元素再移动到父节点**。这样就满足要求了。

我们看看操作过程就更加明白了。

![img](https://oscimg.oschina.net/oscnet/853a8ead34267d029e8d984958c8d4dbea8.jpg)

![img](https://oscimg.oschina.net/oscnet/0ac5a97219474c5fc16270314e655bf0437.jpg)

- 接着删除28，**删除叶子节点**，删除后不满足要求，所以，我们需要考虑向兄弟节点借元素，但是，兄弟节点也没有多的节点（2个），借不了，怎么办呢？如果遇到这种情况，**首先，还是将先将父节点的元素移到该节点，然后，将当前节点及它的兄弟节点中的key合并，形成一个新的节点**。

![img](https://oscimg.oschina.net/oscnet/e5845ae0ae2fe779a932aa452ce650a4b48.jpg)

移动之后，跟兄弟节点合并。

![img](https://oscimg.oschina.net/oscnet/2dfa4b4474986a121c404f2b7b89579616f.jpg)

删除就只有上面的几种情况，根据不同的情况进行删除即可。

上面的这些介绍，相信对于B树已经有一定的了解了，接下来的一部分，我们接着讲解B+树，我相信加上B+树的对比，就更加清晰明了了。



#### B+树

B+树其实和B树是非常相似的，我们首先看看**相同点**。

- 根节点至少一个元素
- 非根节点元素范围：m/2 <= k <= m-1

**不同点**。

- B+树有两种类型的节点：内部结点（也称索引结点）和叶子结点。内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。

- 内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。

- 每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。

- 父节点存有右孩子的第一个元素的索引。

  下面我们看一个B+树的例子，感受感受它吧！

  ![img](https://oscimg.oschina.net/oscnet/bf4d4963b024f6c9fe44d6b26d4f27af54f.jpg)

#### 2.2 插入操作

对于插入操作很简单，只需要记住一个技巧即可：**当节点元素数量大于m-1的时候，按中间元素分裂成左右两部分，中间元素分裂到父节点当做索引存储，但是，本身中间元素还是分裂右边这一部分的**。

下面以一颗5阶B+树的插入过程为例，5阶B+树的节点最少2个元素，最多4个元素。

- 插入5，10，15，20

![img](https://oscimg.oschina.net/oscnet/00114e18a748d2a453007a8b252a43ae8a4.jpg)

- 插入25，此时元素数量大于4个了，分裂

![img](https://oscimg.oschina.net/oscnet/6869626e80377a560361d624f172e1e384f.jpg)

- 接着插入26，30，继续分裂

![img](https://oscimg.oschina.net/oscnet/0a0428579676a0b2543433cafd702029a76.jpg)

![img](https://oscimg.oschina.net/oscnet/57e93e2184d5307f303a6f846cdf900345b.jpg)

有了这几个例子，相信插入操作没什么问题了，下面接着看看删除操作。

#### 删除操作

对于删除操作是比B树简单一些的，因为**叶子节点有指针的存在，向兄弟节点借元素时，不需要通过父节点了，而是可以直接通过兄弟节移动即可（前提是兄弟节点的元素大于m/2），然后更新父节点的索引；如果兄弟节点的元素不大于m/2（兄弟节点也没有多余的元素），则将当前节点和兄弟节点合并，并且删除父节点中的key**，下面我们看看具体的实例。

- 初始状态

![img](https://oscimg.oschina.net/oscnet/365354deaff4bc75d16cf17c3255c46aca4.jpg)

- 删除10，删除后，不满足要求，发现左边兄弟节点有多余的元素，所以去借元素，最后，修改父节点索引

![img](https://oscimg.oschina.net/oscnet/685a53344454eb37d664919a42dac30a45a.jpg)

- 删除元素5，发现不满足要求，并且发现左右兄弟节点都没有多余的元素，所以，可以选择和兄弟节点合并，最后修改父节点索引

![img](https://oscimg.oschina.net/oscnet/f74ef5fff6f4489fbdcaa8d9c113eb48b26.jpg)

- 发现父节点索引也不满足条件，所以，需要做跟上面一步一样的操作

![img](https://oscimg.oschina.net/oscnet/177f38002658f2edfb39a811fed992d58b0.jpg)

这样，B+树的删除操作也就完成了，是不是看完之后，觉得非常简单！



#### 比较



1、B+**树的层级更少**：相较于B树B+每个**非叶子**节点存储的关键字数更多，树的层级更少所以查询数据更快；

2、B+**树查询速度更稳定**：B+所有关键字数据地址都存在**叶子**节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;

3、B+**树天然具备排序功能：**B+树所有的**叶子**节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。

4、B+**树全节点遍历更快：**B+树遍历整棵树只需要遍历所有的**叶子**节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。

**B树**相对于**B+树**的优点是，如果经常访问的数据离根节点很近，而**B树**的**非叶子**节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比**B+树**快。

Q0.数据库索引有哪些，优缺点？

hash索引和B+树索引
hash索引等值查询效率高，但是不能排序，因此不能进行范围查询
B+树索引数据有序，能够进行范围查询

 

**Q1.为什么不用二叉查找树作为数据库索引？**

二叉查找树，查找到指定数据，效率其实很高logn。但是数据库索引文件有可能很大，关系型数据存储了上亿条数据，索引文件大则上G，不可能全部放入内存中，
而是需要的时候换入内存，方式是磁盘页。一般来说树的一个节点就是一个磁盘页。如果使用二叉查找树，那么每个节点存储一个元素，查找到指定元素，需要进行大量的磁盘IO，效率很低。
而B树解决了这个问题，通过单一节点包含多个data，大大降低了树的高度，大大减少了磁盘IO次数。

 

**Q2.B树和二叉查找树的性能对比？**

B树包括B+树的设计思想都是尽可能的降低树的高度，以此降低磁盘IO的次数，因为一个索引节点就表示一个磁盘页，页的换入换出次数越多，表示磁盘IO次数越多，越低效。
B树算法减少定位数据所在的节点时所经历的磁盘IO次数，从而加快存取速度。
假设一个节点可以容纳100个值，那么3层的B树可以容纳100万个数据。（根节点100值，第二层可以存储99个节点（k-1），也就是99*100 个值，第三层可以存储
（99*100-1）*100）结果是近似100万个数据。而如果使用二叉查找树，则需要将近20层，也就是进行20次磁盘IO，性能差距如此之大。
如mongoDB数据库使用，单次查询平均快于Mysql（但侧面来看Mysql至少平均查询耗时差不多）。

 

**Q3.B+对比B树的优点？**

因为B树的每个节点除了存储指向子节点的索引之外，还有data域，因此单一节点存储的指向子节点的索引并不是很多，树高度较高，磁盘IO次数较多，
而B+树单一节点存储的指向子节点的索引更多，B+树空间利用率高，因此B+树高度更低，磁盘IO次数更少，性能更好。
因为B树的中间节点存储了数据，所以整个树的每一层都有可能查找到要查找的数据，查询性能不稳定，
而B+树所有的data都存储在叶子节点，且叶子节点位于同一层，因此查询性能稳定。
B树如果想要进行范围查找，需要频繁的进行二叉树的中序遍历，进行范围查找比较复杂，
B+树要查找的元素都位于叶子节点，且连接形成有序链表，便于范围查找。

 

**Q4.B树，B+树使用场景。**

B树主要用于文件系统，和部分数据库索引，如文档型数据库mongodb
B+树主要用于mysql数据库索引。

 

**Q5.为什么数据库索引不用红黑树而用B+树？**

红黑树当插入删除元素的时候会进行频繁的变色与旋转（左旋，右旋），来保证红黑树的性质，浪费时间。
但是当数据量较小，数据完全可以放入内存中，不需要进行磁盘IO，这时候，红黑树时间复杂度比B+树低。
比如TreeSet TreeMap 和HashMap （jdk1.8）就是使用红黑树作为底层数据结构。
