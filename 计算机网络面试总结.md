# 计算机网络面试总结

[toc]





## OSI七层模型



- **7. 应用层——Application(Layer 7)**

  与其它计算机进行通讯的一个应用，它是对应应用程序的通信服务的。例如，一个没有通信功能的字处理程序就不能执行通信的代码，从事字处理工作的程序员也不关心OSI的第7层。但是，如果添加了一个传输文件的选项，那么字处理器的程序员就需要实现OSI的第7层。

  - 应用层是OSI参考模型的最高层，它是**计算机用户，以及各种应用程序和网络之间的接口**。

  - **直接向用户提供服务，完成用户希望在网络上完成的各种工作。**
    - **用户接口**：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。
    - **实现各种服务**：该层具有的各种应用程序可以完成和实现用户请求的各种服务。
  - 常见协议：DHCP（v6） DNS **FTP** Gopher **HTTP**（SPDY、HTTP/2） IMAP4 IRC NNTP XMPP POP3 SIP **SMTP** SNMP **SSH** **Telnet** **RPC** RTCP RTP RTSP SDP SOAP GTP STUN NTP SSDP

- **6. 表示层——Presentation(Layer 6)**

  这一层的主要功能是定义数据格式及加密。例如，FTP允许你选择以二进制或ASCII格式传输。如果选择二进制，那么发送方和接收方不改变文件的内容。如果选择ASCII格式，发送方将把文本从发送方的字符集转换成标准的ASCII后发送数据。在接收方将标准的ASCII转换成接收方计算机的字符集。

  - 表示层是OSI模型的第六层，它**对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层**。
    　　其主要功能是“**处理用户信息的表示问题，如编码、数据格式转换和加密解密**”等。
      　　表示层的具体功能如下：
      　　　　**数据格式处理**：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。
      　　　　**数据的编码**：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。
      　　　　**压缩和解压缩**：为了减少数据的传输量，这一层还负责数据的压缩与恢复。
      　　　　**数据的加密和解密**：可以提高网络的安全性。

  - 数据提供表示：计算机只能识别0101这种二进制数据，把我们输入、点击的之类的指令翻译成二进制，又把执行后的结果返回。
  - **常见协议**：应用层的HTTP、FTP、Telnet等协议有类似的功能。传输层的TLS/SSL也有类似功能

- **5. 会话层——Session(Layer 5)**

  它定义了如何开始、控制和结束一个会话，包括对多个双向消息的控制和管理，以便在只完成连续消息的一部分时可以通知应用，从而使表示层看到的数据是连续的，在某些情况下，如果表示层收到了所有的数据，则用数据代表表示层。

  - **主要任务**：**向两个实体的表示层提供建立和使用连接的方法**。将不同实体之间的表示层的连接称为会话。因此会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。

    　　用户可以按照半双工、单工和全工的方式建立会话。当建立会话时，用户必须提供他们想要连接的远程地址。而这些地址与MAC（介质访问控制子层）地址或网络层的逻辑地址不同，他们是为用户专门设计的，更便于用户记忆。域名(DN)就是网络上使用的远程地址。会话层的具体功能如下：

    - **会话管理**：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。例如提供单方向会话或双向同时会话，并管理会话中的发送顺序，以及会话所占用时间的长短。
    - **会话流量控制**：提供流量控制和交叉会话功能。
    - **寻址**：使用远程地址建立会话连接。
    - **出错控制**：从逻辑上讲，会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠错。会话控制和远程过程调用均属于这一层的功能。但应注意，**此层检查的错误不是通信介质的错误**，而是磁盘空间、打印机缺纸等高级类的错误。

  - 确定数据是否需要进行网络传输
    - 如果需要，交给下一层：传输层
    - 如果不需要，比如只是保存到文档等
  - **常见协议**：应用层的HTTP、RPC、SDP、RTCP等协议有类似的功能

- **4. 传输层—— Transport(Layer 4)**

  这层的功能包括是否选择差错恢复协议还是无差错恢复协议，及在同一主机上对不同应用的数据流的输入进行复用，还包括对收到的顺序不对的数据包的重新排序功能。

  - **主要任务**：**向用户提供可靠的、端到端的差错和流量控制，保证报文的正确传输。**

  - **主要作用**：向高层屏蔽下层数据通信的具体细节，即向用户透明的传送报文。

    　　传输层提供会话层和网络层之间的传输服务，这种服务从会话层获得数据，并在必要时，对数据进行分割，然后，传输层将数据传送到网络层，并确保数据能准确无误的传送到网络层。因此，传输层负责提供两节点之间数据的可靠传送，当两节点的联系确定之后，传输层负责监督工作。综上，传输层的主要功能如：

    - **传输连接管理**：提供建立、连接和拆除传输连接的功能。传输层在网络层的基础上，提供“面向连接”和“面向无连接”两种服务
    - **处理传输差错**：提供可靠的“面向连接”和不可靠的“面向无连接”的数据传输服务、差错控制和流量控制。在提供“面向连接”服务时，通过这一层传输的数据将由目标设备确认，  如果在指定的时间内未收到确认信息，数据将被重新发送。
    - **监控服务质量**

  - 对报文进行分组（发送时）、组装（接收时）
  - 提供传输协议的选择
    - TCP(传输控制协议)：可靠的，面向连接的传输协议——(可靠、准确的)(慢)
    - UDP(用户数据报协议)：不可靠的，面向无连接的传输协议——(不可靠)(快)
  - 端口封装
    - 源端口
    - 目标端口
  - 差错校验
  - **常见协议**：**TCP**（T/TCP · Fast Open） **UDP** DCCP SCTP RSVP PPTP TLS/SSL

- **3. 网络层——Network(Layer 3)**：是OSI参考模型中最复杂的一层，也是通信子网最高的一层，它在下两层的基础上向资源子网提供服务。

  这层对端到端的包传输进行定义，它定义了能够标识所有结点的逻辑地址，还定义了路由实现的方式和学习的方式。为了适应最大传输单元长度小于包长度的传输介质，网络层还定义了如何将一个包分解成更小的包的分段方法。

  - **主要任务**：**通过路由算法，为报文或分组通过通信子网选择最适当的路径**。该层控制数据链路层与物理层之间的信息转发，建立、维持与终止网络的连接。具体的说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。

    　　**一般的，数据链路层是解决统一网络内节点之间的通信，而网络层主要解决不同子网之间的通信。例如路由选择问题。**

    在实现网络层功能时，需要解决的主要问题如下：
    　　　　寻址：数据链路层中使用的物理地址（如MAC地址）仅解决网络内部的寻址问题。在不同子网之间通信时，为了识别和找到网络中的设备，每一子网中的设备都会被分配一 个唯一的地址。由于各个子网使用的物理技术可能不同，因此这个地址应当是逻辑地址（如IP地址）
    　　　　交换：规定不同的交换方式。常见的交换技术有：线路交换技术和存储转发技术，后者包括报文转发技术和分组转发技术。
    　　　　路由算法：当源节点和路由节点之间存在多条路径时，本层可以根据路由算法，通过网络为数据分组选择最佳路径，并将信息从最合适的路径，由发送端传送的接受端。
    　　　　连接服务：与数据链路层的流量控制不同的是，前者控制的是网络相邻节点间的流量，后者控制的是从源节点到目的节点间的流量。其目的在于防止阻塞，并进行差错检测

  - 典型设备：路由器
    - IP地址编址
      - 源IP
      - 目标IP
    - 路由选择
      - 静态路由
        - 提前写好的规则，会比较麻烦
      - 动态路由
        - 自动选择，可能会选择最短路径，但是带宽可能不是最好的
  - **常见协议**：**IP（v4·v6）** **ICMP**（v6） IGMP IS-IS IPsec BGP RIP OSPF RARP

- **2. 数据链路层——Data Link(Layer 2)**

  它定义了在单个链路上如何传输数据。这些协议与被讨论的各种介质有关。

  - **负责建立和管理节点间的链路。**

  - **主要功能**：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。

  - **具体工作**：接受来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上一层的数据帧，拆装为位流形式的数据转发到物理层；并且还负责处理接受端发回的确认帧的信息，以便提供可靠的数据传输。

    　　该层通常又被分为 介质访问控制(MAC)和逻辑链路控制(LLC)两个子层：
      　　　　**MAC子层**的主要任务是**解决共享型网络中多用户对信道竞争的问题，完成网络介质的访问控制。**
      　　　　**LLC子层**的主要任务是**建立和维护网络连接，执行差错校验、流量控制和链路控制。**

  - 典型设备：交换机（switch）
    - MAC地址编址
    - MAC地址寻址
      - MAC地址和IP找到是哪台电脑
      - 通过PORT查找到对应的服务（一台电脑会有多个服务）
    - 差错校验
      - 差错校验一般都是采用传输层的差错校验
  - **常见协议**：Wi-Fi（IEEE 802.11） ARP WiMAX（IEEE 802.16） ATM DTM **令牌环** 以太网 FDDI **帧中继** GPRS EV-DO HSPA HDLC PPP PPPoE L2TP ISDN SPB STP

- **1. 物理层——Physical(Layer 1)**

  物理层规范是有关传输介质的特性标准，这些规范通常也参考了其他组织制定的标准。连接头、帧、帧的使用、电流、编码及光调制等都属于各种物理层规范中的内容。物理层常用多个规范完成对所有细节的定义。

  - **主要功能**：**利用传输介质为数据链路层提供屋里连接，实现比特流的透明传输**。

  - **作用**：实现相邻计算机节点之间比特流的透明传输，尽可能屏蔽掉具体传输介质与物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。

    　　**透明传输的意义就是：不管传的是什么，所采用的设备只是起一个通道作用，把要传输的内容完好的传到对方！**

  - 典型设备：网线
    - 数据实际传输
    - 电气特性定义
      - 网线有八根线，哪根线传输数据等。。。
  - **常见协议**：以太网 调制解调器 电力线通信 同步光网络 G.709 光导纤维 同轴电缆 双绞线

![OSI7层模型](https://img-blog.csdnimg.cn/20200406184135889.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tpZGR5dDA1,size_16,color_FFFFFF,t_70)

![img](https://pic1.zhimg.com/80/v2-2a159a462cce2e20840a7343769dd074_720w.jpg)

### url到页面的过程

**1、输入url（完整的url包括协议、域名、端口号、路径等）**

**2、浏览器查找当前的url是否存在缓存，并对比缓存是否过期**（这里会涉及到服务器返回的状态码304，强制缓存cache-control、Expires，对比缓存last-Modified、Etag(资源实体标识，是哈希字符串）等）

**3、DNS解析（域名解析）**：域名解析过程就是通过域名去查找与之对应的**服务器IP**的过程。将域名解析成 IP 地址。

   （1）浏览器先检查本地hosts文件是否有这个url映射的IP，有就调用这个IP地址，完成域名解析

   （2）如果没有找到，则去找本地DNS解析器缓存，查找到则返回

   （3）再没找到，就去查找本地DNS服务器，找到返回

   （4）如果还没找到，就向根域名服务器查找，没找到就转发给下级，层层查找，直达查找到IP

**4、建立TCP连接（三次握手建立连接）**

   （1）第一次握手，建立连接，浏览器发生syn包给服务器，等待服务器确认；

　  （2）第二次握手，服务器收到syn包，确认浏览器syn包，并发送syn+ack包给浏览器；

　　（3）第三次握手，浏览器收到服务器syn+ack包，向服务器发送确认包，发送完毕，建立连接；

　  完成三次握手，浏览器和服务器就可以开始传送数据啦~

**5、浏览器向服务器发送http请求**

  http1.0请求方法：GET  POST HEAD

  http1.1新增请求方法：OPTIONS  PUT DELETE  TRACE  CONNECT

**6、服务器响应http请求（包含状态码、响应头、响应体）**

   （1）常见状态码：

​    200：请求数据成功，并返回

　　 301：永久重定向，表示旧地址的资源被永久的移除（资源不可访问）

　　 302：临时重定向，表示旧地址的资源还可以访问，临时跳转到新地址

​    304：资源未修改，可用缓存资源

　　 400：客户端请求语法错误

​    401：请求需要身份认证

​    403：服务器收到请求，但拒绝提供服务

　　 404：请求资源不存在

　　 405：请求方法被服务器禁止

 　  500：服务器错误

 （2）响应体返回给浏览器的资源（html、css、js、图片等）

**7、断开连接：TCP 四次挥手**

**8、浏览器渲染页面**

　　（1）解析html构建DOM和CSSOM树，构建DOM树期间，如果遇到JS，阻塞DOM树和CSSOM树的构建，优先加载js文件（js会阻塞页面加载，所以一般放到html底部进行加载），再加载DOM树和CSSOM树

　　（2）构建渲染树（render Tree）

　　（4）页面渲染过程的重绘(repaint)和重排（reflow），页面渲染完毕后，如若js操作了DOM，浏览器会对页面进行重绘和重排





## TCP/IP

### TCP/IP四层模型

![TCP/IP四层协议](https://img-blog.csdnimg.cn/20200609173100799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQ3OTIzMDE=,size_16,color_FFFFFF,t_70)

![img](https://images2015.cnblogs.com/blog/750327/201608/750327-20160822230932011-1299422087.jpg)

![在这里插入图片描述](https://img-blog.csdn.net/20180930155137505?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NzZG5fa291/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

#### 五层模型

- 多一个物理层
- 教材上的五层结构从上到下：
  - 应用层
  - 传输层
  - 互连网络层
  - 网络接口层
  - 物理层

![img](https://borinboy.oss-cn-shanghai.aliyuncs.com/home/20200912145037.png)

**TCP/IP与OSI最大的不同在于OSI是一个理论上的网络通信模型，而TCP/IP则是实际运行的网络协议。**



### IP

#### **1、IP协议**

　　IP协议概念：规定网络地址的协议叫**ip协议**，它定义的地址称之为**ip地址**，广泛采用的v4版本即ipv4，它规定网络地址由32位2进制表示。

　　IP协议的主要作用：

　　　　一个是为每一台计算机分配IP地址；另一个是确定哪些地址在同一个子网络。

#### 2、子网掩码

　　所谓”子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于IP地址，也是一个32位二进制数字，它的网络部分全部为1，主机部分全部为0。比如，IP地址172.16.10.1，如果已知网络部分是前24位，主机部分是后8位，那么子网络掩码就是11111111.11111111.11111111.00000000，写成十进制就是255.255.255.0。

##### （1）子网掩码作用

　　知道”子网掩码”，我们就能判断，任意两个IP地址是否处在同一个子网络。

##### （2）是否在同一个子网络判断方法

　　方法是将两个IP地址与子网掩码分别进行AND运算（两个数位都为1，运算结果为1，否则为0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是。

#### 3、IP地址

　　IP地址范围：0.0.0.0-255.255.255.255
　　IP地址格式：一个ip地址通常写成四段十进制数，例：172.16.10.1

##### （1）ip地址分两个部分

- 网络部分：标识子网
- 主机部分：标识主机

　　区分网络位和主机位是为了划分子网，划分子网主要是为了避免广播风暴和地址浪费。

　　注意：单纯的ip地址段只是标识了ip地址的种类，从网络部分或主机部分都无法辨识一个ip所处的子网。例：172.16.10.1与172.16.10.2并不能确定二者处于同一子网

##### （2）ip地址分类

　　A类IP地址：一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”， 地址范围从1.0.0.0 到126.0.0.0。可用的A类网络有126个，每个网络能容纳1亿多个主机。

　　B类IP地址：一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳6万多个主机 。

　　C类IP地址：一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.0到223.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。

　　D类IP地址：D类地址第一个字节以“1110”开始，它是一个专门保留的地址。它并不指向特定的网络，目前这一类地址被用在多点广播（Multicast）中。多点广播地址用来一次寻址一组计算机，它标识共享同一协议的一组计算机。

　　E类IP地址：以“llll0”开始，为将来使用保留。

##### （3）特殊地址

　　全零地址："0.0.0.0"对应当前地址。

　　全“1”地址："255.255.255.255"是当前子网的广播地址。

　　回环地址："127.0.0.1"即本机地址

##### （4）127.0.0.1与0.0.0.0区别

　　环回接口(loopback)：

- 传给环回地址（一般是127.0.0.1）的任何数据均作为IP输入。
- 传给广播地址或多播地址的数据报复制一份传给环回接口，然后送到以太网上。这是 因为广播传送和多播传送的定义包含主机本身。
- 任何传给该主机IP地址的数据均送到环回接口。

#### 4、IP报文

　　IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGCP的数据都以IP数据格式传输，要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制－－这被认为是上层协议－－TCP或UDP要做的事情。所以这也就出现了TCP是一个可靠的协议，而UDP就没有那么可靠的区别。

　　![img](https://images2018.cnblogs.com/blog/1311506/201804/1311506-20180405210346320-1091171797.png)　　

　　ip数据包也分为head和data部分，无须为ip包定义单独的栏位，直接放入以太网包的data部分。

　　head：长度为20到60字节

　　data：最长为65,515字节。

　　而以太网数据包的”数据”部分，最长只有1500字节。因此，如果IP数据包超过了1500字节，它就需要分割成几个以太网数据包，分开发送了。

#### 5、ARP协议

　　arp协议介绍：计算机通信依靠广播的方式，所有上层的包到最后都要封装以太网头，然后通过以太网协议发送。通信是基于mac的广播方式实现，但是计算机在发包时，如何获取目标主机的mac就需要通过arp协议。

　　arp协议功能：广播的方式发送数据包，获取目标主机的mac地址。

　　协议工作方式：每台主机ip都是已知的

　　在以太网环境，为了正确地向目的主机传送报文，必须把目的主机的32位IP地址转换成为目的主机48位以太网的地址（MAC地址）。这就需要在互联层有一个服务或功能将IP地址转换为相应的物理地址（MAC地址），这个服务或者功能就是ARP协议。

　　所谓的“地址解析”，就是主机在发送帧之前将目标IP地址转换成目标MAC地址的过程。ARP协议的基本功能就是通过目标设备的IP地址，查询目标设备的MA地址，以保证主机间相互通信的顺利进行。

##### （1）ARP工作示例

　　例如：主机172.16.10.10/24访问172.16.10.11/24

　　首先通过ip地址和子网掩码区分出自己所处的子网

| 场景     | 数据包地址              |
| -------- | ----------------------- |
| 同一子网 | 目标主机mac，目标主机ip |
| 不同子网 | 网关mac，目标主机ip     |

　　然后分析172.16.10.10/24与172.16.10.11/24处于同一网络(如果不是同一网络，那么下表中目标ip为172.16.10.1,通过arp获取的是网关的mac)

|            | 源mac     | 目标mac           | 源ip            | 目标ip          | 数据部分 |
| ---------- | --------- | ----------------- | --------------- | --------------- | -------- |
| 发送端主机 | 发送端mac | FF:FF:FF:FF:FF:FF | 172.16.10.10/24 | 172.16.10.11/24 | 数据     |

　　最后这个包会以广播的方式在发送端所处的自网内传输，所有主机接收后拆开包，发现目标ip为自己的，就响应，返回自己的mac



####  6、ICMP协议

　　当传送IP数据包发生错误－－比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会.

　　ICMP(网络控制报文)协议一般用于检测网络是否通畅，基于ICMP协议的工具主要有Ping和traceroute。

##### （1）ping

　　单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请求，受到请求的主机则用类型码为8的ICMP回应。ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。

##### （2）trace route

　　查看从当前主机到某地址一共经过多少跳路由.

### TCP/UDP

传输层的由来：网络层的ip帮我们区分子网，以太网层的mac帮我们找到主机，再通过端口来标识主机上的应用程序。

　　端口即应用程序与网卡关联的编号。

　　传输层功能：建立端口到端口的通信，补充：端口范围0-65535，0-1023为系统占用端口

　　传输层有两种协议，TCP和UDP

![img](https://images2018.cnblogs.com/blog/1311506/201804/1311506-20180405211641086-722484933.png)

#### 1、TCP协议

　　可靠传输，TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。(流式协议，不间断发送)

　　TCP可靠的缘故：**只要不得到确认，就重新发送数据报，直到得到对方的确认为止。**

**tcp报文：**

 ![img](https://images2018.cnblogs.com/blog/1311506/201804/1311506-20180405220800413-1653158932.png)

##### （1）TCP的3次握手

　　所谓三次握手(Three-way Handshake)，是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。

　　首先Client端发送连接请求报文，Server段接受连接后回复ACK报文，并为这次连接分配资源。Client端接收到ACK报文后也向Server段发生ACK报文，并分配资源，这样TCP连接就建立了。

- **客户端发送一个带 SYN=1，Seq=X 的数据包到服务器端口**（第一次握手，由浏览器发起，告诉服务器我要发送请求了）
- **服务器发回一个带 SYN=1， ACK=X+1， Seq=Y 的响应包以示传达确认信息**（第二次握手，由服务器发起，告诉浏览器我准备接受了，你赶紧发送吧）
- **客户端再回传一个带 ACK=Y+1， Seq=Z 的数据包，代表“握手结束”**（第三次握手，由浏览器发送，告诉服务器，我马上就发了，准备接受吧）

###### 	为什么不是两次握手？

两次握手，客户端收到服务端的应答后进入ESTABLISHED（已建立连接状态），而服务端在收到客户端的连接请求之后就进入了ESTABLISHED状态。如果出现网络拥塞，客户端发送的连接请求报文A过了很久没有到达服务端，会超时重发请求报文B，服务端正确接受并确认应答，连接建立并开始通信传输数据，等通信结束之后释放连接。此时，如果之前失效的连接请求A到达服务端，由于两次握手就能成功建立连接，服务端收到请求A之后进入ESTABLISHED已建立连接状态，等待发送数据或者主动发送数据，此时，客户端已经进入CLISED断开连接状态，服务器会一直等下去，浪费服务器连接资源。

##### （2）TCP的4次挥手

　　TCP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作（中断连接），在socket编程中，任何一方执行close()操作即可产生挥手操作。

　　挥手过程：假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说"我Client端没有数据要发给你了"，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，"告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息"。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，"告诉Client端，好了，我这边数据发完了，准备好关闭连接了"。Client端收到FIN报文后，"就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，"就知道可以断开连接了"。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。

❶ 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

❷ 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

❸ 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。

❹ 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。

❺ 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗ *∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。

❻ 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。




![img](https://images2018.cnblogs.com/blog/1311506/201804/1311506-20180405221910249-914327018.png)

###### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？

建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。

###### 为什么客户端最后还要等待2MSL？

MSL（Maximum Segment Lifetime）可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。TCP允许不同的实现可以设置不同的MSL值。

第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。

第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。


#### 2、UDP协议

　　不可靠传输，”报头”部分一共只有8个字节，总长度不超过65,535字节，正好放进一个IP数据包。

　UDP特点：

- 传送数据前不需要建立连接。
- 尽最大努力交付，无法保证数据准确交付到目标主机，也不需要对接收到的UDP报文进行确认。
- 是面向报文的，将应用层传输的数据封装在UDP包内，不做拆分或合并。
- 没有拥塞控制，因此UDP协议发送速率不受网络拥塞影响
- 支持一对一、一对多、多对多的交互通信
- UDP头部仅占用8个字节，占用较小



#### 3、TCP和UDP对比总结

　　TCP协议虽然安全性很高，但是网络开销大，而UDP协议虽然没有提供安全机制，但是网络开销小，在现在这个网络安全已经相对较高的情况下，为了保证传输的速率，我们一般还是会优先考虑UDP协议！

- TCP面向连接，UDP面向非连接即发送数据前不需要建立链接
- TCP提供可靠的服务（数据传输），UDP无法保证
- TCP面向字节流，UDP面向报文
- TCP数据传输慢，UDP数据传输快

- TCP提供一种面向连接的、可靠的字节流服务
- 在一个TCP连接中，仅有两方进行彼此通信，因此广播和多播不能用于TCP
- TCP使用校验和，确认和重传机制来保证可靠传输
- TCP使用累积确认
- TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制



### TCP拥塞控制

#### 什么是拥塞控制？

在了解拥塞控制之前，先理解一下什么是拥塞。

- **拥塞：** 即在某一时间段，若对网络对资源的需求超过了可用的资源数。网络的性能就要变坏。若网络中有许多资源同时呈现供应不足，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。

了解了拥塞，我们再来看看针对拥塞，所采用的拥塞控制。

- **拥塞控制：** 防止过多的数据注入到网络中，这样可以使网络中的路由器和链路不至过载。拥塞控制所要做的都有一个前提，就是网络能承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，路由器，以及与降低网络传输性能有关的所有因素。

- ∑对资源的需求>可用资源
  **注意**
  单纯的增加网络资源无法解决问题
  例如：把结点的存储空间扩大，更换更高速率的链路，提高结点处理机的运算速度，不仅不能解决问题，而且可能使网络性能更坏。
  原因：网络拥塞是许多因素引起的，单纯的解决一个可能会使上述情况得到一些缓解，但是会把拥塞转移到其他地方。
  扩大结点存储空间——>由于输出链路的容量和处理机的速度并未提高，增大排队等待时间，超时重传，浪费资源。
  更换更高速率的链路——>可能会缓解，，有可能造成各部分不匹配。

#### 拥塞控制的代价

当然，控制的同时也会出现相应的代价。
**拥塞控制代价：** 需要获得网络内部流量分布的信息。在实施拥塞控制之前，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外的开销。拥塞控制还需要将一些资源分配给各个用户单独使用，使得网络资源不能更好地实现共享。

#### 拥塞控制的四种算法

拥塞控制针对不同的网络情况会有不同的算法来应对。
拥塞控制共有四种算法，他们分别是**慢启动**，**拥塞避免**，**快重传**和**快恢复**。

![TCP拥塞控制流程图](https://img-blog.csdn.net/20180610190904311?2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXhuaHM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![从连续收到三个重复的    确认转入拥塞避免](https://img-blog.csdn.net/20180610191132726?2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXhuaHM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

##### 拥塞窗口

在发送数据时， 发送方维持一个**拥塞窗口 cwnd** ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。
发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。
那么拥塞窗口的大小是如何变化的呢？我们从慢开始算法开始讲起。

##### 慢启动

当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。
注：**MSS（最大报文段长度）**：最大报文段长度MSS选项是TCP协议定义的一个选项，MSS选项用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度。
每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。
另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置**cwnd=1**，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。

- 慢开始不是指cwnd的增长速度慢（指数增长），而是指TCP开始发送设置cwnd=1。
- 思路：不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。这里用报文段的个数的拥塞窗口大小举例说明慢开始算法，实时拥塞窗口大小是以字节为单位的。如下图：

![每经过一个传输轮次，cnwd指数增长](https://img-blog.csdn.net/20180610191717379?2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXhuaHM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量（如何设置ssthresh）。慢开始门限ssthresh的用法如下：
  当 cwnd < ssthresh 时，使用上述的慢开始算法。
  当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
  当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。

##### 拥塞避免

塞避免算法：让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口**cwnd加1**，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。

- 拥塞避免并非完全能够避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。
- 思路：让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞控制窗口加一。

无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现**拥塞（其根据就是没有收到确认）**，就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。

**前半段流程**

1. 当TCP连接进行初始化时，把拥塞窗口cwnd置为1。前面已说过，为了便于理解，图中的窗口单位不使用字节而使用报文段的个数。慢开始门限的初始值设置为16个报文段，即 cwnd = 16 。
2. 在执行慢开始算法时，拥塞窗口 cwnd 的初始值为1。以后发送方每收到一个对新报文段的确认ACK，就把拥塞窗口值加1（如下图），然后开始下一轮的传输（图中横坐标为传输轮次）。因此拥塞窗口cwnd 随着传输轮次按指数规律增长。当拥塞窗口cwnd增长到慢开始门限值ssthresh时（即当cwnd=16时），就改为执行拥塞控制算法，拥塞窗口按线 性规律增长。
3. 假定拥塞窗口的数值增长到24时，网络出现超时（这很可能就是网络发生拥塞了）。更新后的ssthresh值变为12（即变为出现超时时的拥塞窗口数值 24的一半），拥塞窗口再重新设置为1，并执行慢开始算法。当cwnd=ssthresh=12时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过 一个往返时间增加一个MSS的大小。

**强调：**“拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。



如果发送方设置的超时计时器时限已到但还没有收到确认，那么很可能是网络出现了拥塞，致使报文段在网络中的某处被丢弃。这时，TCP马上把拥塞窗口 cwnd 减小到1，并执行慢开始算法，同时把慢开始门限值ssthresh减半。**这是不使用快重传的情况。**

##### 快重传

1.快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

![img](https://img-blog.csdn.net/20180610195854523?2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodXhuaHM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

2.由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量。

##### 快恢复（与快重传配合使用）

1.采用快恢复算法时，慢开始只在TCP连接建立时和网络出现超时时才使用。
2.当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。
3.考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小（也就是减半过后的值），然后执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。

注意
发送方窗口的上限值=Min（接受窗口rwnd，拥塞窗口cwnd）
rwnd＞cwnd 接收方的接收能力限制发送方窗口的最大值
rwnd＜cwnd 网络的拥塞限制发送方窗口的最大值





### TCP流量控制

#### 滑动窗口

1.TCP使用**窗口机制**进行流量控制

2.什么是窗口？

- 连接建立时，两端分配一块缓冲区用来存储接收的数据，并将缓冲区的尺寸发送给另一端
  - （发送方和接收方各有一个窗口）
- 正常通信时，接收方发送的**确认信息**中包含了自己剩余的缓冲区尺寸
  - （接收方通过响应报文首部的窗口字段告诉发送方自己的窗口大小，发送方参照该值设置发送窗口大小，进行流量控制）

发送窗口内的数据都允许被发送，接收窗口内的数据都允许被接收

- **发送窗口**：每发送一个数据，窗口右移动一位
- **接收窗口**：每交付给主机一位，窗口向右移动一位

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200905091408647.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDQ3ODM3OA==,size_16,color_FFFFFF,t_70#pic_center)

#### 流量控制

流量控制的目的：控制发送方数据发送速率，保证接收方来得及接收

接收方发送的确认报文中，接收方窗口大小字段可以用来控制发送方窗口大小，进而控制发送速率

实际应用中，为了进行流量控制，发送端会主动时不时发送一个窗口探测的数据段，探测接收端窗口大小

窗口探测数据段仅仅包含一个字节，用来获取最新的窗口大小信息

### 流量控制和拥塞控制的区别

- **拥塞控制**的**任务是确保子网可以承载所到达的流量**。这**是一个全局性问**题，涉及到各方面的行为，包含全部的主机、全部的路由器、路由器内部的存储转发处理过程，以及全部可能会削弱子网承载容量的其他因素。
  - 

- 与此相反，**流控制仅仅与特定的发送方和特定的接收方之间的点到点流量有关**。它的**任务是，确保一个高速的发送方不会持续地以超过接收方吸收能力的速率数据传输。**流控制通常涉及到的做法是，接收方向发送方提供某种直接的反馈，以便告诉发送方别人一端的情形究竟怎么样。

### 滑动窗口与拥塞窗口

1.滑动窗口解决的是发送方和接收方接收数据速率不一致的问题,通过设置滑动窗口(可以通俗的理解为接收方的缓存)可以缓解这一个问题。具体的操作是接收方会向发送方通知自己可以接受数据的大小，而发送方会根据这个数值，发送数据。
2.拥塞窗口用控制全局网络的拥塞情况。通过控制发送方每次发送的流量的多少，用来逐渐试探整体网络的拥塞程度。如果没有拥塞控制，发送方每次发送的数据大小为滑动窗口，在只有2台主机的时候确实是没有问题的，但是如果放到现实的网络大环境中来说是行不通的。因为如果每台主机都发送的窗口大小的数据，那么整个网络系统必然会瘫痪。所以通过在发送方设置拥塞窗口，可以有效缓解网络压力。

### TCP如何保证可靠性

1. **分段** 将报文段分成适合转发的长度

2. **标号** 按照序号判断中间的转发是否有缺失

3. **流量控制** 根据双方的接收发送能力，动态地调整发送方发送窗口的大小，取发送窗口=min(拥塞窗口，接收窗口) （与数据链路层收不下的话返回一个信号告诉发送方自己收不下的流量控制机制不同）

4. **检验和** TCP首部有检验和字段，目的是检验首部+数据部分的数据是否正确，是不是被人篡改或半路出现差错。

5. **超时重传** 发出报文段之后启动定时器，如果重传时间RTT内**没有收到确认**的话，就重传该数据报，也可以采用冗余确认机制（三次接收到同一个ack=k的确认序号，就重传第k个报文段）（快重传中采用的也是冗余重传）

   主要涉及的协议有两种（跟数据链路层的超时重传机制相同）：

   - 停止等待协议 每发送一个报文段就停止，直到收到确认才继续发送，否则超时重传 
   - 滑动窗口协议    
     - 后退N帧协议 GBN： 发送窗口>1，接收窗口=1，即接收方必须按照顺序去接收数据，如果启用了超时重传机制的话，就会重传所有当前已经发送但是没有被确认的报文段 
     - 选择重传协议 SR： 发送窗口>1，接收窗口>1，即接收方无需按照顺序去接收数据，会按照任意顺序接收所有处于接收窗口内的数据。按照如果启用超时重传机制的话只需要重新发送没有收到确认的数据即可。 

6. **拥塞避免** 分为两种：①慢开始，拥塞避免 ②快重传、快恢复
   ![图片说明](https://uploadfiles.nowcoder.com/images/20210330/972694929_1617117127474/154593273E9BAAD4A6E0BBF4F8BA3875)
   检验和的具体工作流程**

**检验和**是TCP和UCP中都有的 要注意检验的是首部和数据字段的有效性

1. 添上伪首部 
2. 首部检验和字段置为0 
3. 伪首部+首部+data部分用二进制反码求和，并将结果填入到检验和字段 
4. 去掉伪首部发送 
5. 发送方接受到该数据之后，首先添上伪首部 
6. 接着计算伪首部加首部加数据部分的二进制反码求和 
7. 如果**全为1**则无差错，去掉伪首部交给网络层，否则丢弃。

## HTTP协议

### HTTP协议概述

HTTP是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）。通过使用网页浏览器、网络爬虫或者其它的工具，客户端发起一个HTTP请求到服务器上指定端口（默认端口为80）。我们称这个客户端为用户代理程序（user agent）。应答的服务器上存储着一些资源，比如HTML文件和图像。我们称这个应答服务器为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如代理服务器、网关或者隧道（tunnel）。

尽管TCP/IP协议是互联网上最流行的应用，HTTP协议中，并没有规定必须使用它或它支持的层。事实上，HTTP可以在任何互联网协议上，或其他网络上实现。HTTP假定其下层协议提供可靠的传输。因此，任何能够提供这种保证的协议都可以被其使用。因此也就是其在TCP/IP协议族使用TCP作为其传输层。

通常，由HTTP客户端发起一个请求，创建一个到服务器指定端口（默认是80端口）的TCP连接。HTTP服务器则在那个端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态，比如"HTTP/1.1 200 OK"，以及返回的内容，如请求的文件、错误消息、或者其它信息。

### HTTP工作原理

HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。

以下是 HTTP 请求/响应的步骤：

\1. 客户端连接到Web服务器
一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如，[http://www.baidu.com](http://www.baidu.com/)。

\2. 发送HTTP请求
通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据4部分组成。

\3. 服务器接受请求并返回HTTP响应
Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据4部分组成。

\4. 释放连接TCP连接
若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;

\5. 客户端浏览器解析HTML内容
客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。

例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程：

1. 浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;
2. 解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接;
3. 浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;
4. 服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;
5. 释放 TCP连接;
6. 浏览器将该 html 文本并显示内容; 　

　　

　　![img](https://images2018.cnblogs.com/blog/877318/201804/877318-20180418160227278-698810818.png)

　　**http协议是基于TCP/IP协议之上的应用层协议。**

　　**基于 请求-响应 的模式**

　　　　HTTP协议规定,请求从客户端发出,最后服务器端响应该请求并 返回。换句话说,肯定是先从客户端开始建立通信的,服务器端在没有 接收到请求之前不会发送响应

　　　　![img](https://images2018.cnblogs.com/blog/877318/201804/877318-20180418160433297-1726664935.png)

　　**无状态保存**

　　　　HTTP是一种不保存状态,即无状态(stateless)协议。HTTP协议 自身不对请求和响应之间的通信状态进行保存。也就是说在HTTP这个 级别,协议对于发送过的请求或响应都不做持久化处理。

　　　　![img](https://images2018.cnblogs.com/blog/877318/201804/877318-20180418160546133-1479186889.png)

　　　　使用HTTP协议,每当有新的请求发送时,就会有对应的新响应产 生。协议本身并不保留之前一切的请求或响应报文的信息。这是为了更快地处理大量事务,确保协议的可伸缩性,而特意把HTTP协议设计成 如此简单的。可是,随着Web的不断发展,因无状态而导致业务处理变得棘手 的情况增多了。比如,用户登录到一家购物网站,即使他跳转到该站的 其他页面后,也需要能继续保持登录状态。针对这个实例,网站为了能 够掌握是谁送出的请求,需要保存用户的状态。HTTP/1.1虽然是无状态协议,但为了实现期望的保持状态功能, 于是引入了Cookie技术。有了Cookie再用HTTP协议通信,就可以管 理状态了。有关Cookie的详细内容稍后讲解。

　　**无连接**

　　　　无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间，并且可以提高并发性能，不能和每个用户建立长久的连接，请求一次相应一次，服务端和客户端就中断了。但是无连接有两种方式，早期的http协议是一个请求一个响应之后，直接就断开了，但是现在的http协议1.1版本不是直接就断开了，而是等几秒钟，这几秒钟是等什么呢，等着用户有后续的操作，如果用户在这几秒钟之内有新的请求，那么还是通过之前的连接通道来收发消息，如果过了这几秒钟用户没有发送新的请求，那么就会断开连接，这样可以提高效率，减少短时间内建立连接的次数，因为建立连接也是耗时的，默认的好像是3秒中现在，但是这个时间是可以通过咱们后端的代码来调整的，自己网站根据自己网站用户的行为来分析统计出一个最优的等待时间。

### HTTP请求方法

HTTP/1.1协议中共定义了八种方法（也叫“动作”）来以不同方式操作指定的资源：

#### GET

向指定的资源发出“显示”请求。使用GET方法应该只用在读取数据，而不应当被用于产生“副作用”的操作中，例如在Web Application中。其中一个原因是GET可能会被网络蜘蛛等随意访问。

#### HEAD

与GET方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中“关于该资源的信息”（元信息或称元数据）。

#### POST

向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求本文中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。

#### PUT

向指定资源位置上传其最新内容。

#### DELETE

请求服务器删除Request-URI所标识的资源。

#### TRACE

回显服务器收到的请求，主要用于测试或诊断。

#### OPTIONS

这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用'*'来代替资源名称，向Web服务器发送OPTIONS请求，可以测试服务器功能是否正常运作。

#### CONNECT

HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接（经由非加密的HTTP代理服务器）。

注意事项：

1. 方法名称是区分大小写的。当某个请求所针对的资源不支持对应的请求方法的时候，服务器应当返回状态码405（Method Not Allowed），当服务器不认识或者不支持对应的请求方法的时候，应当返回状态码501（Not Implemented）。
2. HTTP服务器至少应该实现GET和HEAD方法，其他方法都是可选的。当然，所有的方法支持的实现都应当匹配下述的方法各自的语义定义。此外，除了上述方法，特定的HTTP服务器还能够扩展自定义的方法。例如PATCH（由 RFC 5789 指定的方法）用于将局部修改应用到资源*。*

**请求方式: get与post请求（通过form表单我们自己写写看）**

- GET提交的数据会放在URL之后，也就是请求行里面，以?分割URL和传输数据，参数之间以&相连，如EditBook?name=test1&id=123456.（请求头里面那个content-type做的这种参数形式，后面讲） POST方法是把提交的数据放在HTTP包的请求体中.
- GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制.
- GET与POST请求在服务端获取请求数据方式不同，就是我们自己在服务端取请求数据的时候的方式不同了，这句废话昂。



### get和post的区别

> **注意存放在请求行和请求体的不是方法 而是请求/提交的数据啊喂 post和get方法都是在请求行中啦**

1. get数据明文存放在http请求行的**url**之后，post则是将提交的数据放在**http请求报文**的**请求体**中
2. 受浏览器对**url长度的限制**，get传送数据量应不超过2KB。post传送数据量则一般**无此限制**
3. get**只接受acsii字符**，**post没有限制**，get只支持url编码，post没有限制
4. get不能改变服务器的数据，一般用于从服务器获取数据，是**幂等**的；post可以改变服务器的数据，不是幂等的。
5. get请求可以被浏览器主动缓存，下一次若传输数据相同，则优先返回缓存中的内容，以加快显示速度。post请求不会，除非手动设置一下
6. get请求参数会被完整地保存在浏览器历史记录中，post请求参数则不会保留

**幂等：在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。**

### 常见状态码

- 1xx 表示正在处理
  - 100 continue 一切正常 可以继续发送（据说是http报文中如果有post方法的话 会先把请求行发送过去，然后返回100，然后再发送请求头部和请求体给服务器端） 
- 2xx 成功 表示请求已经正常处理
  - 200 OK 一切正常返回数据 
  - 204 No content 请求正常处理，但是没有数据返回 
  - 206 指定范围返回（http1.1以上支持的断点续传功能相关） 
- 3xx 重定向 浏览器需要一些额外的操作才能完成请求
  - 301 永久性重定向 
  - 302 暂时性重定向（跟http劫持有关，运营商可以通过DNS劫持和http劫持两种，返回一个302，然后让用户跳转到处理好的携带广告的页面） 
  - 303 暂时性重定向 但是服务器端明确说明希望浏览器用get方法来请求资源 
  - 304 浏览器附带了请求的条件，服务器端允许访问，但是不满足请求条件 
- 4xx [客户端]()错误（请求含有词法错误或者无法被执行）
  - 400 [客户端]()的请求有语法错误 
  - 403 forbidden [客户端]()申请访问的资源被禁止访问 
  - 404 Not found [客户端]()申请访问的资源不存在 
  - 405 Method not allowed [客户端]()请求方法被禁止 
- 5xx 服务器端错误（服务器在处理某个正确请求时发生错误）
  - 500 服务器在请求处理时内部出错 
  - 501 服务器不具备完成请求的功能，如无法识别请求方法 
  - 502 服务器作为网关或代理，从上游服务器获得无效响应 
  - 503 Bad Gateway 服务器处于停机维护/超负荷状态 
  - 504 Gateway timeout服务器作为网关或代理，没有及时从上游服务器获得响应

### cookie和session的区别

首先它们都是用于给无连接的http提供身份认证的功能

cookie是服务器在本机存放的小段文本，并随每一个请求发送至同一服务器。cookie分为会话cookie（不设置过期时间，关闭浏览器窗口cookie即失效，保存在内存中）和持久cookie（设置过期时间，关闭再打开浏览器cookie仍存在，直至达到过期时间）。**类似于检查通行证（即请求报文中附带的cookie）来确定用户身份**

session则一般是利用session id实现的（session id是浏览器第一次发送请求时服务器自动生成的唯一标识，并返回给浏览器），cookie中携带该session id，[客户端]()根据该session id将session检索出来。**类似于在服务器上建立一个客户档案，客户来访时需要查询客户档案**

1.cookie是存放在[客户端]()，用于记录用户信息的，比如自动填充用户名和密码；session是存放在服务器端的，用于记录用户的状态，比如购物车的实现。

2.cookie不太安全，可以分析存放在本地的cookie进行cookie欺骗，（也可以用加密[算法]()加密后进行存放），session存放于服务器的内存中，所以安全性高

3.单个cookie保存数据不能超过4k，session没有对存储数据量的限制

> 禁掉cookie的话session仍然可以使用，但是需要使用其他方法获取session id，比如在url后面或者以表单的形式提交给服务器端

### HTTP和HTTPS的区别

HTTP协议是超文本传输协议，采用[客户端]()/服务器的方式，它的特点是：①无连接，建立在TCP连接的基础之上；②无状态，cookie和session可以辅助记录[客户端]()/服务器的状态

1.HTTP协议运行在TCP之上，不提供身份认证和数据加密，所有数据都是以明文的形式传输的；HTTPS以SSL为安全基础，提供了数据加密和服务器端的身份认证（以对称加密的方式为传输的数据进行加密，用数字证书的方式提供服务器端的身份认证），更为安全

2.HTTPS比HTTP需要耗费更多的资源，响应速度也更慢

3.HTTPS需要CA颁布申请证书，通常不是免费的

4.HTTP和HTTPS是完全不同的连接方式，HTTP端口号是80，HTTPS的端口号是443



### http协议的发展历程（1.0 1.1 2.0 3.0）

#### http1.0和http 1.1的主要区别是什么？

1.**连接** HTTP1.0默认使用短连接，每次请求不同的资源都需要重新建立一次连接；HTTP1.1起默认使用长连接，默认开启[keep]()-alive，即同一个TCP连接可以发送和接收多个http请求/响应，这种长连接由流水线方式和非流水线方式，流水线方式是指客户在收到http响应报文之前就能够接着发送新的请求报文，非流水线方式是指客户在收到http响应报文后才能接着发送下一个请求

2.**状态码** HTTP1.1新增24个状态码，409表示请求的资源与资源当前状态发生冲突，410Gone指的是服务器上某个资源被永久删除

3.**带宽优化及网络连接使用** ——http1.1**支持断点续传**，HTTP1.0中不支持只显示对象的一部分（只能显示全部）、且不支持断点续传功能，浪费带宽；HTTP1.1在请求头中引入了range头域，允许只请求资源的某个部分，返回码是206（partial content）

#### http2.0的改进

1. **头部压缩** 减少冗余头信息，用了首部表来跟踪、存储之前的键值对，相同的数据就无需再每次重复请求和响应了
2. **多路复用** 实现由一个tcp连接并发请求。http1.1多个请求的响应之间会被阻塞
3. **服务器推送**：可以主动将资源推送给[客户端]()缓存中
4. **二进制格式**：采用二进制而非文本格式，将所有传输的信息分割为更小的消息和帧（二进制帧）

### 网络攻击

#### DDoS 攻击究竟是什么？

> DDos全名Distributed Denial of Service，翻译成中文就是分布式拒绝服务。指的是处于不同位置的多个攻击者同时向一个或数个目标发动攻击，是一种分布的、协同的大规模攻击方式。单一的DoS攻击一般是采用一对一方式的，它利用网络协议和操作系统的一些缺陷，采用欺骗和伪装的策略来进行网络攻击，使网站服务器充斥大量要求回复的信息，消耗网络带宽或系统资源，导致网络或系统不胜负荷以至于瘫痪而停止提供正常的网络服务。

**如何应对 DDoS 攻击？**

- **高防服务器**
  - 还是拿开的重庆火锅店举例，高防服务器就是我给重庆火锅店增加了两名保安，这两名保安可以让保护店铺不受流氓骚扰，并且还会定期在店铺周围巡逻防止流氓骚扰。
  - 高防服务器主要是指能独立硬防御 50Gbps 以上的服务器，能够帮助网站拒绝服务攻击，定期扫描网络主节点等，这东西是不错，就是贵~

- **黑名单**
  - 面对火锅店里面的流氓，我一怒之下将他们拍照入档，并禁止他们踏入店铺，但是有的时候遇到长得像的人也会禁止他进入店铺。这个就是设置黑名单，此方法秉承的就是“错杀一千，也不放一百”的原则，会封锁正常流量，影响到正常业务。

- **DDoS 清洗**
  - DDos 清洗，就是我发现客人进店几分钟以后，但是一直不点餐，我就把他踢出店里。
  - DDoS 清洗会对用户请求数据进行实时监控，及时发现DOS攻击等异常流量，在不影响正常业务开展的情况下清洗掉这些异常流量。

- **CDN 加速**
  - CDN 加速，我们可以这么理解：为了减少流氓骚扰，我干脆将火锅店开到了线上，承接外卖服务，这样流氓找不到店在哪里，也耍不来流氓了。
  - 在现实中，CDN 服务将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 DDoS 攻击，也可以将流量分散到各个节点中，防止源站崩溃。

#### SYN洪泛攻击如何解决？

攻击者伪装成[客户端]()发送TCP的SYN报文, 当服务器返回ACK确认报文之后, 攻击者不再进行确认, 即不回复确认的确认报文, 这个连接就处于一个**挂起**的状态, 服务器收不到确认报文的话, 会启用超时重传机制, 重复发送ACK给攻击者

这样的话,如果攻击者开启大量这种TCP连接, 导致服务器端有很多个挂起的连接, 并且需要重复发送很多ACK给攻击者, 这样就会消耗服务器的内存 可能导致最后服务器死机, 无法正常工作

**解决方法**

- **降低SYN timeout时间** 使得服务器在没收到确认报文后尽快释放半连接的占用 
- **采用SYN cookie设置** 给每一个请求连接的ip地址分配一个cookie,短时间内如果连续收到某个IP的重复的SYN报文,就认定收到了攻击,以后会自动丢弃该ip地址传送过来的包



#### CSRF

**什么是 CSRF**

　　CSRF, Cross Site Request Forgery, 跨站点请求伪造。举例来讲，某个恶意的网站上有一个指向你的网站的链接，如果某个用户已经登录到你的网站上了，那么当这个用户点击这个恶意网站上的那个链接时，就会向你的网站发来一个请求，你的网站会以为这个请求是用户自己发来的，其实呢，这个请求是那个恶意网站伪造的。

 攻击原理：

CSRF攻击攻击原理及过程如下：

1. 用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A；
2. 在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A；
3. 用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B；
4. 网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A；
5. 浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。 

 **解决**

- token验证机制。在HTTP请求中进行token验证，如果请求中没有token或者token内容不正确，则认为CSRF攻击而拒绝该请求。
- 验证码。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。
- referer识别。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到HTTP。
  1）验证请求来源地址；
  2）关键操作添加验证码；
  3）在请求地址添加 token 并验证。
- 不保存cookie



#### XSS

跨站点脚本攻击，指攻击者通过篡改网页，嵌入恶意脚本程序，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。（**开发者没有将用户输入的文本进行合适的过滤，就贸然插入到 `HTML` 中**）攻击成功后，攻击者可能得到包括更高的权限、私密网页内容和 `cookie` 等各种内容。

- 反射型：发出请求时，XSS代码出现在URL中，作为输入提交到服务器端，服务器端解析后响应，XSS代码随响应内容一起传回给浏览器，最后浏览器解析执行XSS代码。
-   存储型：存储型XSS和反射型XSS的差别仅在于，提交的代码会存储在服务端（数据库，内存，文件系统等），下次请求目标页面时不用再提交XSS代码。（例如：常见的评论，在文本框中输入一段代码，那么就会存放在数据库当中，当再次加载的时候便会执行这样的代码）。

**攻击示例**

- CSS攻击
  用户上传的style节点、script节点、iframe节点等，场景：比如用户在上传的过程中构建了一个style节点，里面写着body display:none !important，大家知道!important在CSS中的优先级最高，如果用户上传的里面真有这样的CSS的话，后果是什么，后果就是任何包含这个CSS文件的页面，用户看到的都是空白页面，因为body是隐藏的，攻击完成！
- JavaScript攻击
  新浪博客写一篇文章，同时偷偷插入一段script，然后发布，发布完成以后如果有人看了，那么我们插入的script就会执行，攻击代码中获取cookie（现在不常有了，个人信息一般会有手机号，邮箱等），接下来就会把查看着的cookie发送的攻击者的服务器。

**防御**

- 编码，对用户的输入不能保持原样，要进一步处理，对用户输入的数据进行HTML Entity编码（十进制或转义字符）；
- 正则过滤，要把不安全或不合理的内容过滤掉，比如移除用户上传的DOM属性，如onerror、onclick、onmousdown、替换script为''等，除了在你的业务中有特殊需求的其它事件都要过滤掉；我们只需要把script的<>尖括号转换了就可以了， 让它形成不了JS的代码块，无法执行就可以了。
  后端也可以替换；前端替换会影响性能
- 前端，服务端，同时需要字符串输入的长度限制。
- 前端，服务端，同时需要对HTML转义处理。将其中的”<”,”>”等特殊字符进行转义编码。
  防 XSS 的核心是必须对输入的数据做过滤处理。